{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLA Predictor application\n",
    "# CLASS Project: https://class-project.eu/\n",
    "\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#\n",
    "#\n",
    "# Created on 25 Mar 2021\n",
    "# @author: Jorge Montero - ATOS\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Para evitar los molestos avisos.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_names = ['go_goroutines','go_memstats_alloc_bytes','go_memstats_gc_cpu_fraction',\n",
    "'go_memstats_gc_sys_bytes', 'go_memstats_heap_alloc_bytes',\n",
    "'go_memstats_heap_idle_bytes', 'go_memstats_heap_inuse_bytes',\n",
    "'go_memstats_heap_objects', 'go_memstats_heap_released_bytes',\n",
    "'go_memstats_heap_sys_bytes', 'go_memstats_last_gc_time_seconds',\n",
    "'go_memstats_mspan_inuse_bytes', 'go_memstats_next_gc_bytes',\n",
    "'go_memstats_other_sys_bytes','go_memstats_stack_inuse_bytes',\n",
    "'go_memstats_stack_sys_bytes', 'go_threads', 'node_boot_time_seconds',\n",
    "'node_entropy_available_bits', 'node_filefd_allocated' ,'node_load1',\n",
    "'node_load15', 'node_load5', 'node_memory_Active_anon_bytes',\n",
    "'node_memory_Active_bytes', 'node_memory_Active_file_bytes',\n",
    "'node_memory_AnonHugePages_bytes', 'node_memory_AnonPages_bytes',\n",
    "'node_memory_Buffers_bytes', 'node_memory_Cached_bytes',\n",
    "'node_memory_Committed_AS_bytes', 'node_memory_DirectMap2M_bytes',\n",
    "'node_memory_DirectMap4k_bytes', 'node_memory_Dirty_bytes',\n",
    "'node_memory_Inactive_anon_bytes', 'node_memory_Inactive_bytes',\n",
    "'node_memory_Inactive_file_bytes', 'node_memory_KernelStack_bytes',\n",
    "'node_memory_Mapped_bytes', 'node_memory_MemAvailable_bytes',\n",
    "'node_memory_MemFree_bytes', 'node_memory_PageTables_bytes',\n",
    "'node_memory_SReclaimable_bytes', 'node_memory_SUnreclaim_bytes',\n",
    "'node_memory_Shmem_bytes', 'node_memory_Slab_bytes', 'node_procs_running', 'node_sockstat_TCP_alloc',\n",
    "'node_sockstat_TCP_mem', 'node_sockstat_TCP_mem_bytes',\n",
    "'node_sockstat_sockets_used', 'node_time_seconds',\n",
    "'node_timex_frequency_adjustment_ratio', 'node_timex_maxerror_seconds',\n",
    "'node_timex_offset_seconds', 'process_resident_memory_bytes',\n",
    "'process_start_time_seconds']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_T1 = pd.read_csv(\"metrics_train/metrics_T1.csv\", sep=';')\n",
    "metrics_T2 = pd.read_csv(\"metrics_train/metrics_T2.csv\", sep=';')\n",
    "metrics_T3 = pd.read_csv(\"metrics_train/metrics_T3.csv\", sep=';')\n",
    "metrics_T4 = pd.read_csv(\"metrics_train/metrics_T4.csv\", sep=';')\n",
    "metrics_T5 = pd.read_csv(\"metrics_train/metrics_T5.csv\", sep=';')\n",
    "metrics_T6 = pd.read_csv(\"metrics_train/metrics_T6.csv\", sep=';')\n",
    "metrics_T7 = pd.read_csv(\"metrics_train/metrics_T7.csv\", sep=';')\n",
    "metrics_T8 = pd.read_csv(\"metrics_train/metrics_T8.csv\", sep=';')\n",
    "metrics_T9 = pd.read_csv(\"metrics_train/metrics_T9.csv\", sep=';')\n",
    "metrics_T10 = pd.read_csv(\"metrics_train/metrics_T10.csv\", sep=';')\n",
    "metrics_T11 = pd.read_csv(\"metrics_train/metrics_T11.csv\", sep=';')\n",
    "metrics_T12 = pd.read_csv(\"metrics_train/metrics_T12.csv\", sep=';')\n",
    "metrics_T13 = pd.read_csv(\"metrics_train/metrics_T13.csv\", sep=';')\n",
    "metrics_T14 = pd.read_csv(\"metrics_train/metrics_T14.csv\", sep=';')\n",
    "metrics_T15 = pd.read_csv(\"metrics_train/metrics_T15.csv\", sep=';')\n",
    "metrics_T16 = pd.read_csv(\"metrics_train/metrics_T16.csv\", sep=';')\n",
    "metrics_T17 = pd.read_csv(\"metrics_train/metrics_T17.csv\", sep=';')\n",
    "metrics_T18 = pd.read_csv(\"metrics_train/metrics_T18.csv\", sep=';')\n",
    "metrics_T19 = pd.read_csv(\"metrics_train/metrics_T19.csv\", sep=';')\n",
    "metrics_T20 = pd.read_csv(\"metrics_train/metrics_T20.csv\", sep=';')\n",
    "metrics_T21 = pd.read_csv(\"metrics_train/metrics_T21.csv\", sep=';')\n",
    "metrics_T22 = pd.read_csv(\"metrics_train/metrics_T22.csv\", sep=';')\n",
    "metrics_T23 = pd.read_csv(\"metrics_train/metrics_T23.csv\", sep=';')\n",
    "metrics_T24 = pd.read_csv(\"metrics_train/metrics_T24.csv\", sep=';')\n",
    "metrics_T25 = pd.read_csv(\"metrics_train/metrics_T25.csv\", sep=';')\n",
    "metrics_T26 = pd.read_csv(\"metrics_train/metrics_T26.csv\", sep=';')\n",
    "metrics_T27 = pd.read_csv(\"metrics_train/metrics_T27.csv\", sep=';')\n",
    "metrics_T28 = pd.read_csv(\"metrics_train/metrics_T28.csv\", sep=';')\n",
    "metrics_T29 = pd.read_csv(\"metrics_train/metrics_T29.csv\", sep=';')\n",
    "metrics_T30 = pd.read_csv(\"metrics_train/metrics_T30.csv\", sep=';')\n",
    "metrics_T31 = pd.read_csv(\"metrics_train/metrics_T31.csv\", sep=';')\n",
    "metrics_T32 = pd.read_csv(\"metrics_train/metrics_T32.csv\", sep=';')\n",
    "metrics_T33 = pd.read_csv(\"metrics_train/metrics_T33.csv\", sep=';')\n",
    "metrics_T34 = pd.read_csv(\"metrics_train/metrics_T34.csv\", sep=';')\n",
    "metrics_T35 = pd.read_csv(\"metrics_train/metrics_T35.csv\", sep=';')\n",
    "metrics_T36 = pd.read_csv(\"metrics_train/metrics_T36.csv\", sep=';')\n",
    "metrics_T37 = pd.read_csv(\"metrics_train/metrics_T37.csv\", sep=';')\n",
    "metrics_T38 = pd.read_csv(\"metrics_train/metrics_T38.csv\", sep=';')\n",
    "metrics_T39 = pd.read_csv(\"metrics_train/metrics_T39.csv\", sep=';')\n",
    "metrics_T40 = pd.read_csv(\"metrics_train/metrics_T40.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "workers = [3,3,3,3,3,3,3,3,3,3,3,3,6,6,6,6,6,6,6,6,6,3,6,6,6,6,1,1,1,3,6,6,9,9,9,9,9,9,9,9]\n",
    "print(len(workers))\n",
    "exectimes = [617820,571378,566439,564199,578790,567978,565619,565052,572151,582628,636311,593063,522618,454466,464412,464266,455849,466922,468000,\n",
    "            709955,693223,595968,463951,455543,472430,459940,588759,600364,594230,599054,457041,464953,407144,415762,416799,424616,413798,\n",
    "            416003,411904,429661]\n",
    "print(len(exectimes))\n",
    "df_array = [metrics_T1,metrics_T2,metrics_T3,metrics_T4,metrics_T5,metrics_T6,metrics_T7,metrics_T8,metrics_T9,metrics_T10,metrics_T11,\n",
    "           metrics_T12,metrics_T13,metrics_T14,metrics_T15,metrics_T16,metrics_T17,metrics_T18,metrics_T19,metrics_T20,metrics_T21,metrics_T22,\n",
    "           metrics_T23,metrics_T24,metrics_T25,metrics_T26,metrics_T27,metrics_T28,metrics_T29,metrics_T30,metrics_T31,metrics_T32,metrics_T33,\n",
    "           metrics_T34,metrics_T35,metrics_T36,metrics_T37,metrics_T38,metrics_T39,metrics_T40]\n",
    "print(len(df_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 58)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_array[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_array = df_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 58)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_array[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train(df_array,metrics_names,workers,exectimes):\n",
    "    metrics_names_mean_all = []\n",
    "\n",
    "    for metrics_df in df_array:\n",
    "        metrics_df_agg = metrics_df.aggregate(\"mean\",axis=0)\n",
    "        metrics_names_mean = []\n",
    "        for metric_name in metrics_names:\n",
    "            metrics_names_mean.append(metrics_df_agg[metric_name])\n",
    "        metrics_names_mean_all.append(metrics_names_mean)\n",
    "            \n",
    "    metrics_MLP = pd.DataFrame(data=metrics_names_mean_all, columns=metrics_names)\n",
    "    metrics_MLP[\"workers\"] = workers\n",
    "    metrics_MLP[\"exectime\"] = exectimes\n",
    "    return metrics_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>go_goroutines</th>\n",
       "      <th>go_memstats_alloc_bytes</th>\n",
       "      <th>go_memstats_gc_cpu_fraction</th>\n",
       "      <th>go_memstats_gc_sys_bytes</th>\n",
       "      <th>go_memstats_heap_alloc_bytes</th>\n",
       "      <th>go_memstats_heap_idle_bytes</th>\n",
       "      <th>go_memstats_heap_inuse_bytes</th>\n",
       "      <th>go_memstats_heap_objects</th>\n",
       "      <th>go_memstats_heap_released_bytes</th>\n",
       "      <th>go_memstats_heap_sys_bytes</th>\n",
       "      <th>...</th>\n",
       "      <th>node_sockstat_TCP_mem_bytes</th>\n",
       "      <th>node_sockstat_sockets_used</th>\n",
       "      <th>node_time_seconds</th>\n",
       "      <th>node_timex_frequency_adjustment_ratio</th>\n",
       "      <th>node_timex_maxerror_seconds</th>\n",
       "      <th>node_timex_offset_seconds</th>\n",
       "      <th>process_resident_memory_bytes</th>\n",
       "      <th>process_start_time_seconds</th>\n",
       "      <th>workers</th>\n",
       "      <th>exectime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.183333</td>\n",
       "      <td>3.061400e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.582216e+06</td>\n",
       "      <td>3.061400e+06</td>\n",
       "      <td>6.159374e+07</td>\n",
       "      <td>4.693743e+06</td>\n",
       "      <td>12598.850000</td>\n",
       "      <td>6.073972e+07</td>\n",
       "      <td>6.628748e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>26760.533333</td>\n",
       "      <td>642.616667</td>\n",
       "      <td>1.614005e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.290683</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>2.575565e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>617820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.183333</td>\n",
       "      <td>3.050053e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.582762e+06</td>\n",
       "      <td>3.050053e+06</td>\n",
       "      <td>6.159360e+07</td>\n",
       "      <td>4.691695e+06</td>\n",
       "      <td>12492.150000</td>\n",
       "      <td>6.065316e+07</td>\n",
       "      <td>6.628529e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>31470.933333</td>\n",
       "      <td>666.600000</td>\n",
       "      <td>1.614006e+09</td>\n",
       "      <td>1.000029</td>\n",
       "      <td>0.403067</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>2.575565e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>571378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.183333</td>\n",
       "      <td>3.265612e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.584401e+06</td>\n",
       "      <td>3.265612e+06</td>\n",
       "      <td>6.139986e+07</td>\n",
       "      <td>4.887620e+06</td>\n",
       "      <td>13427.400000</td>\n",
       "      <td>6.046679e+07</td>\n",
       "      <td>6.628748e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>30993.066667</td>\n",
       "      <td>814.016667</td>\n",
       "      <td>1.614008e+09</td>\n",
       "      <td>1.000030</td>\n",
       "      <td>0.515600</td>\n",
       "      <td>0.003529</td>\n",
       "      <td>2.575565e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>566439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.266667</td>\n",
       "      <td>3.240707e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583854e+06</td>\n",
       "      <td>3.240707e+06</td>\n",
       "      <td>6.144737e+07</td>\n",
       "      <td>4.840107e+06</td>\n",
       "      <td>13024.400000</td>\n",
       "      <td>6.049574e+07</td>\n",
       "      <td>6.628748e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>31402.666667</td>\n",
       "      <td>815.950000</td>\n",
       "      <td>1.614009e+09</td>\n",
       "      <td>1.000030</td>\n",
       "      <td>0.420392</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>2.575565e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>564199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.266667</td>\n",
       "      <td>3.237103e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.582762e+06</td>\n",
       "      <td>3.237103e+06</td>\n",
       "      <td>6.147154e+07</td>\n",
       "      <td>4.815940e+06</td>\n",
       "      <td>12583.116667</td>\n",
       "      <td>6.065289e+07</td>\n",
       "      <td>6.628748e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>21708.800000</td>\n",
       "      <td>600.950000</td>\n",
       "      <td>1.614070e+09</td>\n",
       "      <td>1.000029</td>\n",
       "      <td>0.623192</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>2.575565e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>578790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.283333</td>\n",
       "      <td>3.231249e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.582762e+06</td>\n",
       "      <td>3.231249e+06</td>\n",
       "      <td>6.143672e+07</td>\n",
       "      <td>4.849118e+06</td>\n",
       "      <td>12247.866667</td>\n",
       "      <td>6.059950e+07</td>\n",
       "      <td>6.628584e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>21367.466667</td>\n",
       "      <td>607.866667</td>\n",
       "      <td>1.614071e+09</td>\n",
       "      <td>1.000029</td>\n",
       "      <td>0.539233</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>2.575565e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>567978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>3.211631e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583308e+06</td>\n",
       "      <td>3.211631e+06</td>\n",
       "      <td>6.141611e+07</td>\n",
       "      <td>4.875196e+06</td>\n",
       "      <td>12306.866667</td>\n",
       "      <td>6.050570e+07</td>\n",
       "      <td>6.629130e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>21230.933333</td>\n",
       "      <td>622.066667</td>\n",
       "      <td>1.614072e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.668050</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>2.575565e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>565619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.200000</td>\n",
       "      <td>3.166327e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583308e+06</td>\n",
       "      <td>3.166327e+06</td>\n",
       "      <td>6.143222e+07</td>\n",
       "      <td>4.853077e+06</td>\n",
       "      <td>12945.300000</td>\n",
       "      <td>6.062804e+07</td>\n",
       "      <td>6.628529e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>22459.733333</td>\n",
       "      <td>642.783333</td>\n",
       "      <td>1.614074e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.762933</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>2.575565e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>565052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.166667</td>\n",
       "      <td>3.082571e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.582762e+06</td>\n",
       "      <td>3.082571e+06</td>\n",
       "      <td>6.153748e+07</td>\n",
       "      <td>4.745079e+06</td>\n",
       "      <td>12243.150000</td>\n",
       "      <td>6.073289e+07</td>\n",
       "      <td>6.628256e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>22528.000000</td>\n",
       "      <td>642.900000</td>\n",
       "      <td>1.614075e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.665608</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>2.575565e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>572151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.200000</td>\n",
       "      <td>3.082905e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.582762e+06</td>\n",
       "      <td>3.082905e+06</td>\n",
       "      <td>6.151728e+07</td>\n",
       "      <td>4.763102e+06</td>\n",
       "      <td>12105.966667</td>\n",
       "      <td>6.061588e+07</td>\n",
       "      <td>6.628038e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>23142.400000</td>\n",
       "      <td>639.150000</td>\n",
       "      <td>1.614076e+09</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>0.450217</td>\n",
       "      <td>-0.000392</td>\n",
       "      <td>2.575565e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>582628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.200000</td>\n",
       "      <td>3.041910e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.582216e+06</td>\n",
       "      <td>3.041910e+06</td>\n",
       "      <td>6.153994e+07</td>\n",
       "      <td>4.745353e+06</td>\n",
       "      <td>11714.283333</td>\n",
       "      <td>6.061821e+07</td>\n",
       "      <td>6.628529e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>24371.200000</td>\n",
       "      <td>629.233333</td>\n",
       "      <td>1.614077e+09</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>0.180667</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>2.575565e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>636311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.316667</td>\n",
       "      <td>3.093955e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583308e+06</td>\n",
       "      <td>3.093955e+06</td>\n",
       "      <td>6.153298e+07</td>\n",
       "      <td>4.755593e+06</td>\n",
       "      <td>12174.400000</td>\n",
       "      <td>6.057383e+07</td>\n",
       "      <td>6.628857e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>45602.133333</td>\n",
       "      <td>739.466667</td>\n",
       "      <td>1.614078e+09</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>0.164467</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>2.575565e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>593063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.383333</td>\n",
       "      <td>3.114759e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583854e+06</td>\n",
       "      <td>3.114759e+06</td>\n",
       "      <td>6.153858e+07</td>\n",
       "      <td>4.746172e+06</td>\n",
       "      <td>13219.166667</td>\n",
       "      <td>6.064592e+07</td>\n",
       "      <td>6.628475e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>48878.933333</td>\n",
       "      <td>828.816667</td>\n",
       "      <td>1.614079e+09</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>0.126967</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>2.564601e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>522618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.266667</td>\n",
       "      <td>3.156593e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.582216e+06</td>\n",
       "      <td>3.156593e+06</td>\n",
       "      <td>6.155414e+07</td>\n",
       "      <td>4.727876e+06</td>\n",
       "      <td>12689.533333</td>\n",
       "      <td>6.070682e+07</td>\n",
       "      <td>6.628202e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>24507.733333</td>\n",
       "      <td>600.633333</td>\n",
       "      <td>1.614152e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.547167</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>2.525184e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>454466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.216667</td>\n",
       "      <td>3.197556e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.582762e+06</td>\n",
       "      <td>3.197556e+06</td>\n",
       "      <td>6.149571e+07</td>\n",
       "      <td>4.786313e+06</td>\n",
       "      <td>12930.166667</td>\n",
       "      <td>6.073044e+07</td>\n",
       "      <td>6.628202e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>24780.800000</td>\n",
       "      <td>608.133333</td>\n",
       "      <td>1.614153e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.493267</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>2.525184e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>464412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.233333</td>\n",
       "      <td>3.145829e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583308e+06</td>\n",
       "      <td>3.145829e+06</td>\n",
       "      <td>6.153312e+07</td>\n",
       "      <td>4.749449e+06</td>\n",
       "      <td>12421.833333</td>\n",
       "      <td>6.081399e+07</td>\n",
       "      <td>6.628256e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>25804.800000</td>\n",
       "      <td>613.633333</td>\n",
       "      <td>1.614153e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.370117</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>2.525184e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>464266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.266667</td>\n",
       "      <td>3.117529e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583308e+06</td>\n",
       "      <td>3.117529e+06</td>\n",
       "      <td>6.155564e+07</td>\n",
       "      <td>4.728559e+06</td>\n",
       "      <td>12352.416667</td>\n",
       "      <td>6.085086e+07</td>\n",
       "      <td>6.628420e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>26828.800000</td>\n",
       "      <td>620.083333</td>\n",
       "      <td>1.614154e+09</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>0.343875</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>2.525184e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>455849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.233333</td>\n",
       "      <td>3.153966e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583308e+06</td>\n",
       "      <td>3.153966e+06</td>\n",
       "      <td>6.153271e+07</td>\n",
       "      <td>4.757504e+06</td>\n",
       "      <td>12462.783333</td>\n",
       "      <td>6.083843e+07</td>\n",
       "      <td>6.629021e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>26350.933333</td>\n",
       "      <td>626.900000</td>\n",
       "      <td>1.614155e+09</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>0.293575</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>2.525184e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>466922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.216667</td>\n",
       "      <td>3.141399e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583854e+06</td>\n",
       "      <td>3.141399e+06</td>\n",
       "      <td>6.153039e+07</td>\n",
       "      <td>4.754364e+06</td>\n",
       "      <td>12585.066667</td>\n",
       "      <td>6.087803e+07</td>\n",
       "      <td>6.628475e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>26146.133333</td>\n",
       "      <td>633.866667</td>\n",
       "      <td>1.614156e+09</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>0.177050</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>2.525184e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>468000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.250000</td>\n",
       "      <td>3.125332e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583308e+06</td>\n",
       "      <td>3.125332e+06</td>\n",
       "      <td>6.154008e+07</td>\n",
       "      <td>4.750677e+06</td>\n",
       "      <td>12404.000000</td>\n",
       "      <td>6.084185e+07</td>\n",
       "      <td>6.629076e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>26760.533333</td>\n",
       "      <td>633.833333</td>\n",
       "      <td>1.614156e+09</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>0.175667</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>2.525184e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>709955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.216667</td>\n",
       "      <td>3.184870e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.584401e+06</td>\n",
       "      <td>3.184870e+06</td>\n",
       "      <td>6.149762e+07</td>\n",
       "      <td>4.802970e+06</td>\n",
       "      <td>12555.666667</td>\n",
       "      <td>6.070163e+07</td>\n",
       "      <td>6.630059e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>51814.400000</td>\n",
       "      <td>744.416667</td>\n",
       "      <td>1.614158e+09</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>0.221100</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>2.525184e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>693223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.250000</td>\n",
       "      <td>3.179917e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.584401e+06</td>\n",
       "      <td>3.179917e+06</td>\n",
       "      <td>6.148260e+07</td>\n",
       "      <td>4.817442e+06</td>\n",
       "      <td>12379.566667</td>\n",
       "      <td>6.064415e+07</td>\n",
       "      <td>6.630004e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>66833.066667</td>\n",
       "      <td>825.700000</td>\n",
       "      <td>1.614159e+09</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>0.377842</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>2.525061e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>595968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.333333</td>\n",
       "      <td>3.088848e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583308e+06</td>\n",
       "      <td>3.088848e+06</td>\n",
       "      <td>6.155168e+07</td>\n",
       "      <td>4.728695e+06</td>\n",
       "      <td>12502.283333</td>\n",
       "      <td>6.072866e+07</td>\n",
       "      <td>6.628038e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>24917.333333</td>\n",
       "      <td>599.966667</td>\n",
       "      <td>1.614247e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.451825</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>463951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>3.132133e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583308e+06</td>\n",
       "      <td>3.132133e+06</td>\n",
       "      <td>6.150991e+07</td>\n",
       "      <td>4.764467e+06</td>\n",
       "      <td>12728.350000</td>\n",
       "      <td>6.072784e+07</td>\n",
       "      <td>6.627437e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>24849.066667</td>\n",
       "      <td>606.383333</td>\n",
       "      <td>1.614248e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.401525</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>455543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7.266667</td>\n",
       "      <td>3.131358e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583308e+06</td>\n",
       "      <td>3.131358e+06</td>\n",
       "      <td>6.151182e+07</td>\n",
       "      <td>4.757641e+06</td>\n",
       "      <td>12778.716667</td>\n",
       "      <td>6.075924e+07</td>\n",
       "      <td>6.626946e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>24917.333333</td>\n",
       "      <td>612.800000</td>\n",
       "      <td>1.614248e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.362383</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>472430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.216667</td>\n",
       "      <td>3.071790e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583854e+06</td>\n",
       "      <td>3.071790e+06</td>\n",
       "      <td>6.154977e+07</td>\n",
       "      <td>4.724599e+06</td>\n",
       "      <td>12309.333333</td>\n",
       "      <td>6.076266e+07</td>\n",
       "      <td>6.627437e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>24098.133333</td>\n",
       "      <td>619.950000</td>\n",
       "      <td>1.614249e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.255167</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>459940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.216667</td>\n",
       "      <td>3.067474e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.582762e+06</td>\n",
       "      <td>3.067474e+06</td>\n",
       "      <td>6.157257e+07</td>\n",
       "      <td>4.698522e+06</td>\n",
       "      <td>12226.833333</td>\n",
       "      <td>6.088021e+07</td>\n",
       "      <td>6.627110e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>22937.600000</td>\n",
       "      <td>626.700000</td>\n",
       "      <td>1.614250e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.224650</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>588759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.166667</td>\n",
       "      <td>3.048570e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.582762e+06</td>\n",
       "      <td>3.048570e+06</td>\n",
       "      <td>6.160698e+07</td>\n",
       "      <td>4.663023e+06</td>\n",
       "      <td>12049.066667</td>\n",
       "      <td>6.086820e+07</td>\n",
       "      <td>6.627000e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>23074.133333</td>\n",
       "      <td>624.516667</td>\n",
       "      <td>1.614251e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.301942</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>600364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7.150000</td>\n",
       "      <td>3.030577e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583854e+06</td>\n",
       "      <td>3.030577e+06</td>\n",
       "      <td>6.163920e+07</td>\n",
       "      <td>4.637901e+06</td>\n",
       "      <td>11867.683333</td>\n",
       "      <td>6.082901e+07</td>\n",
       "      <td>6.627710e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>23688.533333</td>\n",
       "      <td>613.933333</td>\n",
       "      <td>1.614252e+09</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>0.620325</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>594230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7.183333</td>\n",
       "      <td>3.078557e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583308e+06</td>\n",
       "      <td>3.078557e+06</td>\n",
       "      <td>6.159223e+07</td>\n",
       "      <td>4.682138e+06</td>\n",
       "      <td>12264.650000</td>\n",
       "      <td>6.082792e+07</td>\n",
       "      <td>6.627437e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>23210.666667</td>\n",
       "      <td>604.383333</td>\n",
       "      <td>1.614253e+09</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>1.096500</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>599054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7.183333</td>\n",
       "      <td>3.162726e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.584401e+06</td>\n",
       "      <td>3.162726e+06</td>\n",
       "      <td>6.146567e+07</td>\n",
       "      <td>4.820173e+06</td>\n",
       "      <td>11895.283333</td>\n",
       "      <td>6.053970e+07</td>\n",
       "      <td>6.628584e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>25600.000000</td>\n",
       "      <td>626.383333</td>\n",
       "      <td>1.614255e+09</td>\n",
       "      <td>1.000029</td>\n",
       "      <td>1.610733</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>457041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7.183333</td>\n",
       "      <td>3.186663e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.584401e+06</td>\n",
       "      <td>3.186663e+06</td>\n",
       "      <td>6.142525e+07</td>\n",
       "      <td>4.858948e+06</td>\n",
       "      <td>12198.750000</td>\n",
       "      <td>6.050475e+07</td>\n",
       "      <td>6.628420e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>24917.333333</td>\n",
       "      <td>634.600000</td>\n",
       "      <td>1.614255e+09</td>\n",
       "      <td>1.000031</td>\n",
       "      <td>1.403317</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>464953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7.233333</td>\n",
       "      <td>3.427877e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583854e+06</td>\n",
       "      <td>3.427877e+06</td>\n",
       "      <td>6.123397e+07</td>\n",
       "      <td>5.017463e+06</td>\n",
       "      <td>14346.983333</td>\n",
       "      <td>6.041190e+07</td>\n",
       "      <td>6.625143e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>27170.133333</td>\n",
       "      <td>600.333333</td>\n",
       "      <td>1.614584e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.512467</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>407144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7.250000</td>\n",
       "      <td>3.318961e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583854e+06</td>\n",
       "      <td>3.318961e+06</td>\n",
       "      <td>6.132176e+07</td>\n",
       "      <td>4.937865e+06</td>\n",
       "      <td>13732.833333</td>\n",
       "      <td>6.048659e+07</td>\n",
       "      <td>6.625963e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>27033.600000</td>\n",
       "      <td>612.950000</td>\n",
       "      <td>1.614585e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.586375</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>415762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>3.219563e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.582762e+06</td>\n",
       "      <td>3.219563e+06</td>\n",
       "      <td>6.138730e+07</td>\n",
       "      <td>4.875605e+06</td>\n",
       "      <td>13063.116667</td>\n",
       "      <td>6.052072e+07</td>\n",
       "      <td>6.626290e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>27238.400000</td>\n",
       "      <td>624.816667</td>\n",
       "      <td>1.614585e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.741475</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>416799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7.250000</td>\n",
       "      <td>3.104713e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.582762e+06</td>\n",
       "      <td>3.104713e+06</td>\n",
       "      <td>6.147072e+07</td>\n",
       "      <td>4.793276e+06</td>\n",
       "      <td>12216.133333</td>\n",
       "      <td>6.061425e+07</td>\n",
       "      <td>6.626400e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>26214.400000</td>\n",
       "      <td>641.033333</td>\n",
       "      <td>1.614586e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.939500</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>424616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7.250000</td>\n",
       "      <td>3.053771e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.582216e+06</td>\n",
       "      <td>3.053771e+06</td>\n",
       "      <td>6.152670e+07</td>\n",
       "      <td>4.744943e+06</td>\n",
       "      <td>12025.266667</td>\n",
       "      <td>6.069589e+07</td>\n",
       "      <td>6.627164e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>25395.200000</td>\n",
       "      <td>654.966667</td>\n",
       "      <td>1.614587e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.929000</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>413798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>3.095292e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.582216e+06</td>\n",
       "      <td>3.095292e+06</td>\n",
       "      <td>6.147004e+07</td>\n",
       "      <td>4.800512e+06</td>\n",
       "      <td>12109.300000</td>\n",
       "      <td>6.063596e+07</td>\n",
       "      <td>6.627055e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>24917.333333</td>\n",
       "      <td>666.500000</td>\n",
       "      <td>1.614588e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.844533</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>416003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7.233333</td>\n",
       "      <td>3.160096e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.582216e+06</td>\n",
       "      <td>3.160096e+06</td>\n",
       "      <td>6.143317e+07</td>\n",
       "      <td>4.827546e+06</td>\n",
       "      <td>13147.116667</td>\n",
       "      <td>6.065671e+07</td>\n",
       "      <td>6.626072e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>25395.200000</td>\n",
       "      <td>664.333333</td>\n",
       "      <td>1.614588e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.699025</td>\n",
       "      <td>-0.000396</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>411904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7.250000</td>\n",
       "      <td>3.158439e+06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.583308e+06</td>\n",
       "      <td>3.158439e+06</td>\n",
       "      <td>6.145488e+07</td>\n",
       "      <td>4.803652e+06</td>\n",
       "      <td>13297.183333</td>\n",
       "      <td>6.066285e+07</td>\n",
       "      <td>6.625853e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>24917.333333</td>\n",
       "      <td>667.650000</td>\n",
       "      <td>1.614589e+09</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>0.483225</td>\n",
       "      <td>-0.000310</td>\n",
       "      <td>2.524365e+07</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>429661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    go_goroutines  go_memstats_alloc_bytes  go_memstats_gc_cpu_fraction  \\\n",
       "0        7.183333             3.061400e+06                     0.000015   \n",
       "1        7.183333             3.050053e+06                     0.000015   \n",
       "2        7.183333             3.265612e+06                     0.000015   \n",
       "3        7.266667             3.240707e+06                     0.000015   \n",
       "4        7.266667             3.237103e+06                     0.000015   \n",
       "5        7.283333             3.231249e+06                     0.000015   \n",
       "6        7.300000             3.211631e+06                     0.000015   \n",
       "7        7.200000             3.166327e+06                     0.000015   \n",
       "8        7.166667             3.082571e+06                     0.000015   \n",
       "9        7.200000             3.082905e+06                     0.000015   \n",
       "10       7.200000             3.041910e+06                     0.000015   \n",
       "11       7.316667             3.093955e+06                     0.000015   \n",
       "12       7.383333             3.114759e+06                     0.000015   \n",
       "13       7.266667             3.156593e+06                     0.000015   \n",
       "14       7.216667             3.197556e+06                     0.000015   \n",
       "15       7.233333             3.145829e+06                     0.000015   \n",
       "16       7.266667             3.117529e+06                     0.000015   \n",
       "17       7.233333             3.153966e+06                     0.000015   \n",
       "18       7.216667             3.141399e+06                     0.000015   \n",
       "19       7.250000             3.125332e+06                     0.000015   \n",
       "20       7.216667             3.184870e+06                     0.000015   \n",
       "21       7.250000             3.179917e+06                     0.000015   \n",
       "22       7.333333             3.088848e+06                     0.000015   \n",
       "23       7.300000             3.132133e+06                     0.000015   \n",
       "24       7.266667             3.131358e+06                     0.000015   \n",
       "25       7.216667             3.071790e+06                     0.000015   \n",
       "26       7.216667             3.067474e+06                     0.000015   \n",
       "27       7.166667             3.048570e+06                     0.000015   \n",
       "28       7.150000             3.030577e+06                     0.000015   \n",
       "29       7.183333             3.078557e+06                     0.000015   \n",
       "30       7.183333             3.162726e+06                     0.000015   \n",
       "31       7.183333             3.186663e+06                     0.000015   \n",
       "32       7.233333             3.427877e+06                     0.000015   \n",
       "33       7.250000             3.318961e+06                     0.000015   \n",
       "34       7.300000             3.219563e+06                     0.000015   \n",
       "35       7.250000             3.104713e+06                     0.000015   \n",
       "36       7.250000             3.053771e+06                     0.000015   \n",
       "37       7.300000             3.095292e+06                     0.000015   \n",
       "38       7.233333             3.160096e+06                     0.000015   \n",
       "39       7.250000             3.158439e+06                     0.000015   \n",
       "\n",
       "    go_memstats_gc_sys_bytes  go_memstats_heap_alloc_bytes  \\\n",
       "0               3.582216e+06                  3.061400e+06   \n",
       "1               3.582762e+06                  3.050053e+06   \n",
       "2               3.584401e+06                  3.265612e+06   \n",
       "3               3.583854e+06                  3.240707e+06   \n",
       "4               3.582762e+06                  3.237103e+06   \n",
       "5               3.582762e+06                  3.231249e+06   \n",
       "6               3.583308e+06                  3.211631e+06   \n",
       "7               3.583308e+06                  3.166327e+06   \n",
       "8               3.582762e+06                  3.082571e+06   \n",
       "9               3.582762e+06                  3.082905e+06   \n",
       "10              3.582216e+06                  3.041910e+06   \n",
       "11              3.583308e+06                  3.093955e+06   \n",
       "12              3.583854e+06                  3.114759e+06   \n",
       "13              3.582216e+06                  3.156593e+06   \n",
       "14              3.582762e+06                  3.197556e+06   \n",
       "15              3.583308e+06                  3.145829e+06   \n",
       "16              3.583308e+06                  3.117529e+06   \n",
       "17              3.583308e+06                  3.153966e+06   \n",
       "18              3.583854e+06                  3.141399e+06   \n",
       "19              3.583308e+06                  3.125332e+06   \n",
       "20              3.584401e+06                  3.184870e+06   \n",
       "21              3.584401e+06                  3.179917e+06   \n",
       "22              3.583308e+06                  3.088848e+06   \n",
       "23              3.583308e+06                  3.132133e+06   \n",
       "24              3.583308e+06                  3.131358e+06   \n",
       "25              3.583854e+06                  3.071790e+06   \n",
       "26              3.582762e+06                  3.067474e+06   \n",
       "27              3.582762e+06                  3.048570e+06   \n",
       "28              3.583854e+06                  3.030577e+06   \n",
       "29              3.583308e+06                  3.078557e+06   \n",
       "30              3.584401e+06                  3.162726e+06   \n",
       "31              3.584401e+06                  3.186663e+06   \n",
       "32              3.583854e+06                  3.427877e+06   \n",
       "33              3.583854e+06                  3.318961e+06   \n",
       "34              3.582762e+06                  3.219563e+06   \n",
       "35              3.582762e+06                  3.104713e+06   \n",
       "36              3.582216e+06                  3.053771e+06   \n",
       "37              3.582216e+06                  3.095292e+06   \n",
       "38              3.582216e+06                  3.160096e+06   \n",
       "39              3.583308e+06                  3.158439e+06   \n",
       "\n",
       "    go_memstats_heap_idle_bytes  go_memstats_heap_inuse_bytes  \\\n",
       "0                  6.159374e+07                  4.693743e+06   \n",
       "1                  6.159360e+07                  4.691695e+06   \n",
       "2                  6.139986e+07                  4.887620e+06   \n",
       "3                  6.144737e+07                  4.840107e+06   \n",
       "4                  6.147154e+07                  4.815940e+06   \n",
       "5                  6.143672e+07                  4.849118e+06   \n",
       "6                  6.141611e+07                  4.875196e+06   \n",
       "7                  6.143222e+07                  4.853077e+06   \n",
       "8                  6.153748e+07                  4.745079e+06   \n",
       "9                  6.151728e+07                  4.763102e+06   \n",
       "10                 6.153994e+07                  4.745353e+06   \n",
       "11                 6.153298e+07                  4.755593e+06   \n",
       "12                 6.153858e+07                  4.746172e+06   \n",
       "13                 6.155414e+07                  4.727876e+06   \n",
       "14                 6.149571e+07                  4.786313e+06   \n",
       "15                 6.153312e+07                  4.749449e+06   \n",
       "16                 6.155564e+07                  4.728559e+06   \n",
       "17                 6.153271e+07                  4.757504e+06   \n",
       "18                 6.153039e+07                  4.754364e+06   \n",
       "19                 6.154008e+07                  4.750677e+06   \n",
       "20                 6.149762e+07                  4.802970e+06   \n",
       "21                 6.148260e+07                  4.817442e+06   \n",
       "22                 6.155168e+07                  4.728695e+06   \n",
       "23                 6.150991e+07                  4.764467e+06   \n",
       "24                 6.151182e+07                  4.757641e+06   \n",
       "25                 6.154977e+07                  4.724599e+06   \n",
       "26                 6.157257e+07                  4.698522e+06   \n",
       "27                 6.160698e+07                  4.663023e+06   \n",
       "28                 6.163920e+07                  4.637901e+06   \n",
       "29                 6.159223e+07                  4.682138e+06   \n",
       "30                 6.146567e+07                  4.820173e+06   \n",
       "31                 6.142525e+07                  4.858948e+06   \n",
       "32                 6.123397e+07                  5.017463e+06   \n",
       "33                 6.132176e+07                  4.937865e+06   \n",
       "34                 6.138730e+07                  4.875605e+06   \n",
       "35                 6.147072e+07                  4.793276e+06   \n",
       "36                 6.152670e+07                  4.744943e+06   \n",
       "37                 6.147004e+07                  4.800512e+06   \n",
       "38                 6.143317e+07                  4.827546e+06   \n",
       "39                 6.145488e+07                  4.803652e+06   \n",
       "\n",
       "    go_memstats_heap_objects  go_memstats_heap_released_bytes  \\\n",
       "0               12598.850000                     6.073972e+07   \n",
       "1               12492.150000                     6.065316e+07   \n",
       "2               13427.400000                     6.046679e+07   \n",
       "3               13024.400000                     6.049574e+07   \n",
       "4               12583.116667                     6.065289e+07   \n",
       "5               12247.866667                     6.059950e+07   \n",
       "6               12306.866667                     6.050570e+07   \n",
       "7               12945.300000                     6.062804e+07   \n",
       "8               12243.150000                     6.073289e+07   \n",
       "9               12105.966667                     6.061588e+07   \n",
       "10              11714.283333                     6.061821e+07   \n",
       "11              12174.400000                     6.057383e+07   \n",
       "12              13219.166667                     6.064592e+07   \n",
       "13              12689.533333                     6.070682e+07   \n",
       "14              12930.166667                     6.073044e+07   \n",
       "15              12421.833333                     6.081399e+07   \n",
       "16              12352.416667                     6.085086e+07   \n",
       "17              12462.783333                     6.083843e+07   \n",
       "18              12585.066667                     6.087803e+07   \n",
       "19              12404.000000                     6.084185e+07   \n",
       "20              12555.666667                     6.070163e+07   \n",
       "21              12379.566667                     6.064415e+07   \n",
       "22              12502.283333                     6.072866e+07   \n",
       "23              12728.350000                     6.072784e+07   \n",
       "24              12778.716667                     6.075924e+07   \n",
       "25              12309.333333                     6.076266e+07   \n",
       "26              12226.833333                     6.088021e+07   \n",
       "27              12049.066667                     6.086820e+07   \n",
       "28              11867.683333                     6.082901e+07   \n",
       "29              12264.650000                     6.082792e+07   \n",
       "30              11895.283333                     6.053970e+07   \n",
       "31              12198.750000                     6.050475e+07   \n",
       "32              14346.983333                     6.041190e+07   \n",
       "33              13732.833333                     6.048659e+07   \n",
       "34              13063.116667                     6.052072e+07   \n",
       "35              12216.133333                     6.061425e+07   \n",
       "36              12025.266667                     6.069589e+07   \n",
       "37              12109.300000                     6.063596e+07   \n",
       "38              13147.116667                     6.065671e+07   \n",
       "39              13297.183333                     6.066285e+07   \n",
       "\n",
       "    go_memstats_heap_sys_bytes  ...  node_sockstat_TCP_mem_bytes  \\\n",
       "0                 6.628748e+07  ...                 26760.533333   \n",
       "1                 6.628529e+07  ...                 31470.933333   \n",
       "2                 6.628748e+07  ...                 30993.066667   \n",
       "3                 6.628748e+07  ...                 31402.666667   \n",
       "4                 6.628748e+07  ...                 21708.800000   \n",
       "5                 6.628584e+07  ...                 21367.466667   \n",
       "6                 6.629130e+07  ...                 21230.933333   \n",
       "7                 6.628529e+07  ...                 22459.733333   \n",
       "8                 6.628256e+07  ...                 22528.000000   \n",
       "9                 6.628038e+07  ...                 23142.400000   \n",
       "10                6.628529e+07  ...                 24371.200000   \n",
       "11                6.628857e+07  ...                 45602.133333   \n",
       "12                6.628475e+07  ...                 48878.933333   \n",
       "13                6.628202e+07  ...                 24507.733333   \n",
       "14                6.628202e+07  ...                 24780.800000   \n",
       "15                6.628256e+07  ...                 25804.800000   \n",
       "16                6.628420e+07  ...                 26828.800000   \n",
       "17                6.629021e+07  ...                 26350.933333   \n",
       "18                6.628475e+07  ...                 26146.133333   \n",
       "19                6.629076e+07  ...                 26760.533333   \n",
       "20                6.630059e+07  ...                 51814.400000   \n",
       "21                6.630004e+07  ...                 66833.066667   \n",
       "22                6.628038e+07  ...                 24917.333333   \n",
       "23                6.627437e+07  ...                 24849.066667   \n",
       "24                6.626946e+07  ...                 24917.333333   \n",
       "25                6.627437e+07  ...                 24098.133333   \n",
       "26                6.627110e+07  ...                 22937.600000   \n",
       "27                6.627000e+07  ...                 23074.133333   \n",
       "28                6.627710e+07  ...                 23688.533333   \n",
       "29                6.627437e+07  ...                 23210.666667   \n",
       "30                6.628584e+07  ...                 25600.000000   \n",
       "31                6.628420e+07  ...                 24917.333333   \n",
       "32                6.625143e+07  ...                 27170.133333   \n",
       "33                6.625963e+07  ...                 27033.600000   \n",
       "34                6.626290e+07  ...                 27238.400000   \n",
       "35                6.626400e+07  ...                 26214.400000   \n",
       "36                6.627164e+07  ...                 25395.200000   \n",
       "37                6.627055e+07  ...                 24917.333333   \n",
       "38                6.626072e+07  ...                 25395.200000   \n",
       "39                6.625853e+07  ...                 24917.333333   \n",
       "\n",
       "    node_sockstat_sockets_used  node_time_seconds  \\\n",
       "0                   642.616667       1.614005e+09   \n",
       "1                   666.600000       1.614006e+09   \n",
       "2                   814.016667       1.614008e+09   \n",
       "3                   815.950000       1.614009e+09   \n",
       "4                   600.950000       1.614070e+09   \n",
       "5                   607.866667       1.614071e+09   \n",
       "6                   622.066667       1.614072e+09   \n",
       "7                   642.783333       1.614074e+09   \n",
       "8                   642.900000       1.614075e+09   \n",
       "9                   639.150000       1.614076e+09   \n",
       "10                  629.233333       1.614077e+09   \n",
       "11                  739.466667       1.614078e+09   \n",
       "12                  828.816667       1.614079e+09   \n",
       "13                  600.633333       1.614152e+09   \n",
       "14                  608.133333       1.614153e+09   \n",
       "15                  613.633333       1.614153e+09   \n",
       "16                  620.083333       1.614154e+09   \n",
       "17                  626.900000       1.614155e+09   \n",
       "18                  633.866667       1.614156e+09   \n",
       "19                  633.833333       1.614156e+09   \n",
       "20                  744.416667       1.614158e+09   \n",
       "21                  825.700000       1.614159e+09   \n",
       "22                  599.966667       1.614247e+09   \n",
       "23                  606.383333       1.614248e+09   \n",
       "24                  612.800000       1.614248e+09   \n",
       "25                  619.950000       1.614249e+09   \n",
       "26                  626.700000       1.614250e+09   \n",
       "27                  624.516667       1.614251e+09   \n",
       "28                  613.933333       1.614252e+09   \n",
       "29                  604.383333       1.614253e+09   \n",
       "30                  626.383333       1.614255e+09   \n",
       "31                  634.600000       1.614255e+09   \n",
       "32                  600.333333       1.614584e+09   \n",
       "33                  612.950000       1.614585e+09   \n",
       "34                  624.816667       1.614585e+09   \n",
       "35                  641.033333       1.614586e+09   \n",
       "36                  654.966667       1.614587e+09   \n",
       "37                  666.500000       1.614588e+09   \n",
       "38                  664.333333       1.614588e+09   \n",
       "39                  667.650000       1.614589e+09   \n",
       "\n",
       "    node_timex_frequency_adjustment_ratio  node_timex_maxerror_seconds  \\\n",
       "0                                1.000028                     0.290683   \n",
       "1                                1.000029                     0.403067   \n",
       "2                                1.000030                     0.515600   \n",
       "3                                1.000030                     0.420392   \n",
       "4                                1.000029                     0.623192   \n",
       "5                                1.000029                     0.539233   \n",
       "6                                1.000028                     0.668050   \n",
       "7                                1.000028                     0.762933   \n",
       "8                                1.000028                     0.665608   \n",
       "9                                1.000027                     0.450217   \n",
       "10                               1.000026                     0.180667   \n",
       "11                               1.000026                     0.164467   \n",
       "12                               1.000027                     0.126967   \n",
       "13                               1.000028                     0.547167   \n",
       "14                               1.000028                     0.493267   \n",
       "15                               1.000028                     0.370117   \n",
       "16                               1.000027                     0.343875   \n",
       "17                               1.000027                     0.293575   \n",
       "18                               1.000027                     0.177050   \n",
       "19                               1.000027                     0.175667   \n",
       "20                               1.000027                     0.221100   \n",
       "21                               1.000027                     0.377842   \n",
       "22                               1.000028                     0.451825   \n",
       "23                               1.000028                     0.401525   \n",
       "24                               1.000028                     0.362383   \n",
       "25                               1.000028                     0.255167   \n",
       "26                               1.000028                     0.224650   \n",
       "27                               1.000028                     0.301942   \n",
       "28                               1.000027                     0.620325   \n",
       "29                               1.000027                     1.096500   \n",
       "30                               1.000029                     1.610733   \n",
       "31                               1.000031                     1.403317   \n",
       "32                               1.000028                     0.512467   \n",
       "33                               1.000028                     0.586375   \n",
       "34                               1.000028                     0.741475   \n",
       "35                               1.000028                     0.939500   \n",
       "36                               1.000028                     0.929000   \n",
       "37                               1.000028                     0.844533   \n",
       "38                               1.000028                     0.699025   \n",
       "39                               1.000027                     0.483225   \n",
       "\n",
       "    node_timex_offset_seconds  process_resident_memory_bytes  \\\n",
       "0                    0.000075                   2.575565e+07   \n",
       "1                    0.000121                   2.575565e+07   \n",
       "2                    0.003529                   2.575565e+07   \n",
       "3                    0.000552                   2.575565e+07   \n",
       "4                   -0.000006                   2.575565e+07   \n",
       "5                   -0.000074                   2.575565e+07   \n",
       "6                   -0.000109                   2.575565e+07   \n",
       "7                   -0.000415                   2.575565e+07   \n",
       "8                   -0.000222                   2.575565e+07   \n",
       "9                   -0.000392                   2.575565e+07   \n",
       "10                   0.000443                   2.575565e+07   \n",
       "11                   0.001324                   2.575565e+07   \n",
       "12                   0.002087                   2.564601e+07   \n",
       "13                  -0.000069                   2.525184e+07   \n",
       "14                   0.000011                   2.525184e+07   \n",
       "15                   0.000079                   2.525184e+07   \n",
       "16                   0.000325                   2.525184e+07   \n",
       "17                   0.000512                   2.525184e+07   \n",
       "18                   0.000713                   2.525184e+07   \n",
       "19                   0.000785                   2.525184e+07   \n",
       "20                   0.000473                   2.525184e+07   \n",
       "21                   0.000286                   2.525061e+07   \n",
       "22                  -0.000020                   2.524365e+07   \n",
       "23                  -0.000036                   2.524365e+07   \n",
       "24                  -0.000056                   2.524365e+07   \n",
       "25                  -0.000014                   2.524365e+07   \n",
       "26                   0.000043                   2.524365e+07   \n",
       "27                   0.000061                   2.524365e+07   \n",
       "28                   0.000075                   2.524365e+07   \n",
       "29                   0.000016                   2.524365e+07   \n",
       "30                   0.002758                   2.524365e+07   \n",
       "31                   0.004533                   2.524365e+07   \n",
       "32                   0.000111                   2.524365e+07   \n",
       "33                   0.000118                   2.524365e+07   \n",
       "34                   0.000121                   2.524365e+07   \n",
       "35                   0.000108                   2.524365e+07   \n",
       "36                  -0.000443                   2.524365e+07   \n",
       "37                  -0.000455                   2.524365e+07   \n",
       "38                  -0.000396                   2.524365e+07   \n",
       "39                  -0.000310                   2.524365e+07   \n",
       "\n",
       "    process_start_time_seconds  workers  exectime  \n",
       "0                 1.612092e+09        3    617820  \n",
       "1                 1.612092e+09        3    571378  \n",
       "2                 1.612092e+09        3    566439  \n",
       "3                 1.612092e+09        3    564199  \n",
       "4                 1.612092e+09        3    578790  \n",
       "5                 1.612092e+09        3    567978  \n",
       "6                 1.612092e+09        3    565619  \n",
       "7                 1.612092e+09        3    565052  \n",
       "8                 1.612092e+09        3    572151  \n",
       "9                 1.612092e+09        3    582628  \n",
       "10                1.612092e+09        3    636311  \n",
       "11                1.612092e+09        3    593063  \n",
       "12                1.612092e+09        6    522618  \n",
       "13                1.612092e+09        6    454466  \n",
       "14                1.612092e+09        6    464412  \n",
       "15                1.612092e+09        6    464266  \n",
       "16                1.612092e+09        6    455849  \n",
       "17                1.612092e+09        6    466922  \n",
       "18                1.612092e+09        6    468000  \n",
       "19                1.612092e+09        6    709955  \n",
       "20                1.612092e+09        6    693223  \n",
       "21                1.612092e+09        3    595968  \n",
       "22                1.612092e+09        6    463951  \n",
       "23                1.612092e+09        6    455543  \n",
       "24                1.612092e+09        6    472430  \n",
       "25                1.612092e+09        6    459940  \n",
       "26                1.612092e+09        1    588759  \n",
       "27                1.612092e+09        1    600364  \n",
       "28                1.612092e+09        1    594230  \n",
       "29                1.612092e+09        3    599054  \n",
       "30                1.612092e+09        6    457041  \n",
       "31                1.612092e+09        6    464953  \n",
       "32                1.612092e+09        9    407144  \n",
       "33                1.612092e+09        9    415762  \n",
       "34                1.612092e+09        9    416799  \n",
       "35                1.612092e+09        9    424616  \n",
       "36                1.612092e+09        9    413798  \n",
       "37                1.612092e+09        9    416003  \n",
       "38                1.612092e+09        9    411904  \n",
       "39                1.612092e+09        9    429661  \n",
       "\n",
       "[40 rows x 59 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_MLP = create_train(new_df_array,metrics_names,workers,exectimes)\n",
    "metrics_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 58)                3422      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                1770      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 128       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 5,794\n",
      "Trainable params: 5,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 120772078250.6667\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 22577871872.0000\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 13955398314.6667\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 12480878933.3333\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8834884608.0000\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6310147072.0000\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9197653845.3333\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5843004885.3333\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 5132910464.0000\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5350849792.0000\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5278114986.6667\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5348340053.3333\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7112094464.0000\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 748us/step - loss: 5695620352.0000\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4753357610.6667\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4398225536.0000\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4751767210.6667\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4670030720.0000\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4426362410.6667\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5173327616.0000\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 995us/step - loss: 4565433344.0000\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4470831146.6667\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4858831744.0000\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4581073322.6667\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4821068544.0000\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4742776874.6667\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3419259733.3333\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4686474752.0000\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4211062336.0000\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5151885568.0000\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4464598912.0000\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4455692074.6667\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4513980586.6667\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5273547264.0000\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4779817813.3333\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4468357504.0000\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5130944597.3333\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4046535978.6667\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3656642581.3333\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5211902634.6667\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 5060759893.3333\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5018942464.0000\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5496864170.6667\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4864139690.6667\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3120627114.6667\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4244767061.3333\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4559380480.0000\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4042240298.6667\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5234206848.0000\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7012697856.0000\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7327865344.0000\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5110136405.3333\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6553120512.0000\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5008225365.3333\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4014357034.6667\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4652864896.0000\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4202038528.0000\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3072866581.3333\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4457983829.3333\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5371113045.3333\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5067499349.3333\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4236432128.0000\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3964841984.0000\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3648713130.6667\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4167652821.3333\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 3611368917.3333\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4082169216.0000\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3709961557.3333\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4427743402.6667\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4183291776.0000\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4743737088.0000\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 4697665280.0000\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3920795605.3333\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4940688938.6667\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4844647850.6667\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3682337408.0000\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5884077226.6667\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3581249536.0000\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3831931605.3333\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3973202730.6667\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3385463637.3333\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4122223829.3333\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3501855957.3333\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3475755818.6667\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3407762730.6667\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4386665472.0000\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4550148864.0000\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4939484629.3333\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3489668330.6667\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3031959765.3333\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4935355904.0000\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5188469077.3333\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5076046506.6667\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 998us/step - loss: 4561122432.0000\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4004673365.3333\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3705696554.6667\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4095744768.0000\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4645342634.6667\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4358445504.0000\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6394537557.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c9588ae940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "batch_size=8\n",
    "epochs = 100\n",
    "\n",
    "#https://keras.io/activations/\n",
    "#https://keras.io/initializers/\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(58, input_dim=58, kernel_initializer='normal', activation='relu'))\n",
    "mlp.add(Dense(30, kernel_initializer='normal', activation='relu'))\n",
    "mlp.add(Dense(15, kernel_initializer='normal', activation='relu'))\n",
    "mlp.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "mlp.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "    \n",
    "mlp.summary()\n",
    "\n",
    "mlp.compile(loss='mean_squared_error',\n",
    "              optimizer='adam')\n",
    "\n",
    "# load dataset\n",
    "dataset = metrics_MLP.values\n",
    "# split into input (X) and output (Y) variables\n",
    "x_train = dataset[:,0:58]\n",
    "y_train = dataset[:,58]\n",
    "\n",
    "mlp.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 4356948992.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4356948992.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58,)\n",
      "(1, 58)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0].shape)\n",
    "print(x_train[0:1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[559920.5]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.predict(x_train[0:1])\n",
    "# 617820"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[567130.75]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.predict(x_train[1:2])\n",
    "# 571378"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.save('sla_model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "mlp2 = load_model('sla_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[559920.5]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.predict(x_train[0:1])\n",
    "# 617820"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get last hour of metrics to predict the exectime with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prometheus_api_client import PrometheusConnect\n",
    "from prometheus_api_client.utils import parse_datetime\n",
    "from datetime import timedelta\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prom = PrometheusConnect(url =\"http://192.168.7.42:9091/\", disable_ssl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeseries_from_metric(metric_name,start_time,end_time,chunk_size):\n",
    "    metric_data = prom.get_metric_range_data(\n",
    "        metric_name,  # this is the metric name and label config\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        chunk_size=chunk_size,\n",
    "    )\n",
    "    \n",
    "    # do some process to it: merging all timeseries values to one, and get the aggregated value\n",
    "    metric_d_all_df = pd.DataFrame()\n",
    "    if metric_data:\n",
    "        for i in range(0,len(metric_data)):\n",
    "            metric_d_df = pd.DataFrame(metric_data[i][\"values\"],columns=[\"timestamp\", metric_name+str(i)])\n",
    "            metric_d_df['timestamp']= pd.to_datetime(metric_d_df['timestamp'], unit='s')\n",
    "            metric_d_df[metric_name+str(i)]= pd.to_numeric(metric_d_df[metric_name+str(i)], errors='coerce')\n",
    "            metric_d_df.set_index('timestamp', inplace=True)\n",
    "\n",
    "            metric_d_all_df = pd.concat([metric_d_all_df, metric_d_df], axis=0)\n",
    "\n",
    "        #metric_d_all_df = metric_d_all_df.groupby(pd.Grouper(freq='1Min')).aggregate(\"last\")\n",
    "\n",
    "        metric_d_agg_df = metric_d_all_df\n",
    "        metric_d_agg_df[metric_name] = metric_d_all_df.aggregate(\"mean\", axis=1)\n",
    "        #return metric_d_agg_df[metric_name]     \n",
    "\n",
    "        metric_data_insert = []\n",
    "        metric_data_insert_time = metric_d_agg_df.index.values\n",
    "        metric_data_insert_val = metric_d_agg_df[metric_name].values\n",
    "        for i in range(0,len(metric_data_insert_time)):\n",
    "            metric_data_insert.append([metric_data_insert_time[i],metric_data_insert_val[i]])\n",
    "        metric_data_df = pd.DataFrame(metric_data_insert,columns=[\"timestamp\", metric_name])\n",
    "        metric_data_df['timestamp']= pd.to_datetime(metric_data_df['timestamp'], unit='s')\n",
    "        metric_data_df[metric_name]= pd.to_numeric(metric_data_df[metric_name], errors='coerce')\n",
    "        metric_data_df.set_index('timestamp', inplace=True)\n",
    "        return metric_data_df\n",
    "    \n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_values_for_metrics(start_time, end_time, chunk_size, metrics_names):    \n",
    "    metrics_all_df = pd.DataFrame()\n",
    "    \n",
    "    print(end_time)\n",
    "    for metric_name in metrics_names:\n",
    "        print(metric_name)\n",
    "        metric_data_df = get_timeseries_from_metric(metric_name,start_time,end_time,chunk_size)\n",
    "        #print(metric_data_df)\n",
    "        if not metric_data_df.empty:\n",
    "            metrics_all_df = pd.concat([metrics_all_df, metric_data_df], axis=0)\n",
    "            \n",
    "    metrics_all_df = metrics_all_df.groupby(pd.Grouper(freq='1Min')).aggregate(\"last\")\n",
    "    \n",
    "    print(\"-------------------------------------\")\n",
    "    return metrics_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-03 11:34:25.369608\n",
      "go_goroutines\n",
      "go_memstats_alloc_bytes\n",
      "go_memstats_gc_cpu_fraction\n",
      "go_memstats_gc_sys_bytes\n",
      "go_memstats_heap_alloc_bytes\n",
      "go_memstats_heap_idle_bytes\n",
      "go_memstats_heap_inuse_bytes\n",
      "go_memstats_heap_objects\n",
      "go_memstats_heap_released_bytes\n",
      "go_memstats_heap_sys_bytes\n",
      "go_memstats_last_gc_time_seconds\n",
      "go_memstats_mspan_inuse_bytes\n",
      "go_memstats_next_gc_bytes\n",
      "go_memstats_other_sys_bytes\n",
      "go_memstats_stack_inuse_bytes\n",
      "go_memstats_stack_sys_bytes\n",
      "go_threads\n",
      "node_boot_time_seconds\n",
      "node_entropy_available_bits\n",
      "node_filefd_allocated\n",
      "node_load1\n",
      "node_load15\n",
      "node_load5\n",
      "node_memory_Active_anon_bytes\n",
      "node_memory_Active_bytes\n",
      "node_memory_Active_file_bytes\n",
      "node_memory_AnonHugePages_bytes\n",
      "node_memory_AnonPages_bytes\n",
      "node_memory_Buffers_bytes\n",
      "node_memory_Cached_bytes\n",
      "node_memory_Committed_AS_bytes\n",
      "node_memory_DirectMap2M_bytes\n",
      "node_memory_DirectMap4k_bytes\n",
      "node_memory_Dirty_bytes\n",
      "node_memory_Inactive_anon_bytes\n",
      "node_memory_Inactive_bytes\n",
      "node_memory_Inactive_file_bytes\n",
      "node_memory_KernelStack_bytes\n",
      "node_memory_Mapped_bytes\n",
      "node_memory_MemAvailable_bytes\n",
      "node_memory_MemFree_bytes\n",
      "node_memory_PageTables_bytes\n",
      "node_memory_SReclaimable_bytes\n",
      "node_memory_SUnreclaim_bytes\n",
      "node_memory_Shmem_bytes\n",
      "node_memory_Slab_bytes\n",
      "node_procs_running\n",
      "node_sockstat_TCP_alloc\n",
      "node_sockstat_TCP_mem\n",
      "node_sockstat_TCP_mem_bytes\n",
      "node_sockstat_sockets_used\n",
      "node_time_seconds\n",
      "node_timex_frequency_adjustment_ratio\n",
      "node_timex_maxerror_seconds\n",
      "node_timex_offset_seconds\n",
      "process_resident_memory_bytes\n",
      "process_start_time_seconds\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = parse_datetime(\"1h\")\n",
    "end_time = parse_datetime(\"now\")\n",
    "chunk_size = timedelta(minutes=10)\n",
    "\n",
    "metrics_now = historical_values_for_metrics(start_time, end_time, chunk_size, metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train(df_array,metrics_names,workers,exectimes):\n",
    "    metrics_names_mean_all = []\n",
    "\n",
    "    for metrics_df in df_array:\n",
    "        metrics_df_agg = metrics_df.aggregate(\"mean\",axis=0)\n",
    "        metrics_names_mean = []\n",
    "        for metric_name in metrics_names:\n",
    "            metrics_names_mean.append(metrics_df_agg[metric_name])\n",
    "        metrics_names_mean_all.append(metrics_names_mean)\n",
    "            \n",
    "    metrics_MLP = pd.DataFrame(data=metrics_names_mean_all, columns=metrics_names)\n",
    "    metrics_MLP[\"workers\"] = workers\n",
    "    metrics_MLP[\"exectime\"] = exectimes\n",
    "    return metrics_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>go_goroutines</th>\n",
       "      <th>go_memstats_alloc_bytes</th>\n",
       "      <th>go_memstats_gc_cpu_fraction</th>\n",
       "      <th>go_memstats_gc_sys_bytes</th>\n",
       "      <th>go_memstats_heap_alloc_bytes</th>\n",
       "      <th>go_memstats_heap_idle_bytes</th>\n",
       "      <th>go_memstats_heap_inuse_bytes</th>\n",
       "      <th>go_memstats_heap_objects</th>\n",
       "      <th>go_memstats_heap_released_bytes</th>\n",
       "      <th>go_memstats_heap_sys_bytes</th>\n",
       "      <th>...</th>\n",
       "      <th>node_sockstat_TCP_mem_bytes</th>\n",
       "      <th>node_sockstat_sockets_used</th>\n",
       "      <th>node_time_seconds</th>\n",
       "      <th>node_timex_frequency_adjustment_ratio</th>\n",
       "      <th>node_timex_maxerror_seconds</th>\n",
       "      <th>node_timex_offset_seconds</th>\n",
       "      <th>process_resident_memory_bytes</th>\n",
       "      <th>process_start_time_seconds</th>\n",
       "      <th>workers</th>\n",
       "      <th>exectime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.442623</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>3.615993e+06</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>6.132034e+07</td>\n",
       "      <td>4.938702e+06</td>\n",
       "      <td>13645.672131</td>\n",
       "      <td>6.033327e+07</td>\n",
       "      <td>6.625904e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>25381.770492</td>\n",
       "      <td>610.688525</td>\n",
       "      <td>1.614766e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.525549</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>2.514796e+07</td>\n",
       "      <td>1.612124e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.442623</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>3.615993e+06</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>6.132034e+07</td>\n",
       "      <td>4.938702e+06</td>\n",
       "      <td>13645.672131</td>\n",
       "      <td>6.033327e+07</td>\n",
       "      <td>6.625904e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>25381.770492</td>\n",
       "      <td>610.688525</td>\n",
       "      <td>1.614766e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.525549</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>2.514796e+07</td>\n",
       "      <td>1.612124e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.442623</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>3.615993e+06</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>6.132034e+07</td>\n",
       "      <td>4.938702e+06</td>\n",
       "      <td>13645.672131</td>\n",
       "      <td>6.033327e+07</td>\n",
       "      <td>6.625904e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>25381.770492</td>\n",
       "      <td>610.688525</td>\n",
       "      <td>1.614766e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.525549</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>2.514796e+07</td>\n",
       "      <td>1.612124e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.442623</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>3.615993e+06</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>6.132034e+07</td>\n",
       "      <td>4.938702e+06</td>\n",
       "      <td>13645.672131</td>\n",
       "      <td>6.033327e+07</td>\n",
       "      <td>6.625904e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>25381.770492</td>\n",
       "      <td>610.688525</td>\n",
       "      <td>1.614766e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.525549</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>2.514796e+07</td>\n",
       "      <td>1.612124e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.442623</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>3.615993e+06</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>6.132034e+07</td>\n",
       "      <td>4.938702e+06</td>\n",
       "      <td>13645.672131</td>\n",
       "      <td>6.033327e+07</td>\n",
       "      <td>6.625904e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>25381.770492</td>\n",
       "      <td>610.688525</td>\n",
       "      <td>1.614766e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.525549</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>2.514796e+07</td>\n",
       "      <td>1.612124e+09</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.442623</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>3.615993e+06</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>6.132034e+07</td>\n",
       "      <td>4.938702e+06</td>\n",
       "      <td>13645.672131</td>\n",
       "      <td>6.033327e+07</td>\n",
       "      <td>6.625904e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>25381.770492</td>\n",
       "      <td>610.688525</td>\n",
       "      <td>1.614766e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.525549</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>2.514796e+07</td>\n",
       "      <td>1.612124e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.442623</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>3.615993e+06</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>6.132034e+07</td>\n",
       "      <td>4.938702e+06</td>\n",
       "      <td>13645.672131</td>\n",
       "      <td>6.033327e+07</td>\n",
       "      <td>6.625904e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>25381.770492</td>\n",
       "      <td>610.688525</td>\n",
       "      <td>1.614766e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.525549</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>2.514796e+07</td>\n",
       "      <td>1.612124e+09</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.442623</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>3.615993e+06</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>6.132034e+07</td>\n",
       "      <td>4.938702e+06</td>\n",
       "      <td>13645.672131</td>\n",
       "      <td>6.033327e+07</td>\n",
       "      <td>6.625904e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>25381.770492</td>\n",
       "      <td>610.688525</td>\n",
       "      <td>1.614766e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.525549</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>2.514796e+07</td>\n",
       "      <td>1.612124e+09</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.442623</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>3.615993e+06</td>\n",
       "      <td>3.326889e+06</td>\n",
       "      <td>6.132034e+07</td>\n",
       "      <td>4.938702e+06</td>\n",
       "      <td>13645.672131</td>\n",
       "      <td>6.033327e+07</td>\n",
       "      <td>6.625904e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>25381.770492</td>\n",
       "      <td>610.688525</td>\n",
       "      <td>1.614766e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.525549</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>2.514796e+07</td>\n",
       "      <td>1.612124e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   go_goroutines  go_memstats_alloc_bytes  go_memstats_gc_cpu_fraction  \\\n",
       "0       7.442623             3.326889e+06                     0.000018   \n",
       "1       7.442623             3.326889e+06                     0.000018   \n",
       "2       7.442623             3.326889e+06                     0.000018   \n",
       "3       7.442623             3.326889e+06                     0.000018   \n",
       "4       7.442623             3.326889e+06                     0.000018   \n",
       "5       7.442623             3.326889e+06                     0.000018   \n",
       "6       7.442623             3.326889e+06                     0.000018   \n",
       "7       7.442623             3.326889e+06                     0.000018   \n",
       "8       7.442623             3.326889e+06                     0.000018   \n",
       "\n",
       "   go_memstats_gc_sys_bytes  go_memstats_heap_alloc_bytes  \\\n",
       "0              3.615993e+06                  3.326889e+06   \n",
       "1              3.615993e+06                  3.326889e+06   \n",
       "2              3.615993e+06                  3.326889e+06   \n",
       "3              3.615993e+06                  3.326889e+06   \n",
       "4              3.615993e+06                  3.326889e+06   \n",
       "5              3.615993e+06                  3.326889e+06   \n",
       "6              3.615993e+06                  3.326889e+06   \n",
       "7              3.615993e+06                  3.326889e+06   \n",
       "8              3.615993e+06                  3.326889e+06   \n",
       "\n",
       "   go_memstats_heap_idle_bytes  go_memstats_heap_inuse_bytes  \\\n",
       "0                 6.132034e+07                  4.938702e+06   \n",
       "1                 6.132034e+07                  4.938702e+06   \n",
       "2                 6.132034e+07                  4.938702e+06   \n",
       "3                 6.132034e+07                  4.938702e+06   \n",
       "4                 6.132034e+07                  4.938702e+06   \n",
       "5                 6.132034e+07                  4.938702e+06   \n",
       "6                 6.132034e+07                  4.938702e+06   \n",
       "7                 6.132034e+07                  4.938702e+06   \n",
       "8                 6.132034e+07                  4.938702e+06   \n",
       "\n",
       "   go_memstats_heap_objects  go_memstats_heap_released_bytes  \\\n",
       "0              13645.672131                     6.033327e+07   \n",
       "1              13645.672131                     6.033327e+07   \n",
       "2              13645.672131                     6.033327e+07   \n",
       "3              13645.672131                     6.033327e+07   \n",
       "4              13645.672131                     6.033327e+07   \n",
       "5              13645.672131                     6.033327e+07   \n",
       "6              13645.672131                     6.033327e+07   \n",
       "7              13645.672131                     6.033327e+07   \n",
       "8              13645.672131                     6.033327e+07   \n",
       "\n",
       "   go_memstats_heap_sys_bytes  ...  node_sockstat_TCP_mem_bytes  \\\n",
       "0                6.625904e+07  ...                 25381.770492   \n",
       "1                6.625904e+07  ...                 25381.770492   \n",
       "2                6.625904e+07  ...                 25381.770492   \n",
       "3                6.625904e+07  ...                 25381.770492   \n",
       "4                6.625904e+07  ...                 25381.770492   \n",
       "5                6.625904e+07  ...                 25381.770492   \n",
       "6                6.625904e+07  ...                 25381.770492   \n",
       "7                6.625904e+07  ...                 25381.770492   \n",
       "8                6.625904e+07  ...                 25381.770492   \n",
       "\n",
       "   node_sockstat_sockets_used  node_time_seconds  \\\n",
       "0                  610.688525       1.614766e+09   \n",
       "1                  610.688525       1.614766e+09   \n",
       "2                  610.688525       1.614766e+09   \n",
       "3                  610.688525       1.614766e+09   \n",
       "4                  610.688525       1.614766e+09   \n",
       "5                  610.688525       1.614766e+09   \n",
       "6                  610.688525       1.614766e+09   \n",
       "7                  610.688525       1.614766e+09   \n",
       "8                  610.688525       1.614766e+09   \n",
       "\n",
       "   node_timex_frequency_adjustment_ratio  node_timex_maxerror_seconds  \\\n",
       "0                               1.000028                     0.525549   \n",
       "1                               1.000028                     0.525549   \n",
       "2                               1.000028                     0.525549   \n",
       "3                               1.000028                     0.525549   \n",
       "4                               1.000028                     0.525549   \n",
       "5                               1.000028                     0.525549   \n",
       "6                               1.000028                     0.525549   \n",
       "7                               1.000028                     0.525549   \n",
       "8                               1.000028                     0.525549   \n",
       "\n",
       "   node_timex_offset_seconds  process_resident_memory_bytes  \\\n",
       "0                   0.000056                   2.514796e+07   \n",
       "1                   0.000056                   2.514796e+07   \n",
       "2                   0.000056                   2.514796e+07   \n",
       "3                   0.000056                   2.514796e+07   \n",
       "4                   0.000056                   2.514796e+07   \n",
       "5                   0.000056                   2.514796e+07   \n",
       "6                   0.000056                   2.514796e+07   \n",
       "7                   0.000056                   2.514796e+07   \n",
       "8                   0.000056                   2.514796e+07   \n",
       "\n",
       "   process_start_time_seconds  workers  exectime  \n",
       "0                1.612124e+09        1         0  \n",
       "1                1.612124e+09        2         0  \n",
       "2                1.612124e+09        3         0  \n",
       "3                1.612124e+09        4         0  \n",
       "4                1.612124e+09        5         0  \n",
       "5                1.612124e+09        6         0  \n",
       "6                1.612124e+09        7         0  \n",
       "7                1.612124e+09        8         0  \n",
       "8                1.612124e+09        9         0  \n",
       "\n",
       "[9 rows x 59 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_MLP = create_train([metrics_now,metrics_now,metrics_now,metrics_now,metrics_now,metrics_now,metrics_now,metrics_now,metrics_now],metrics_names,[1,2,3,4,5,6,7,8,9],[0,0,0,0,0,0,0,0,0])\n",
    "metrics_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "mlp2 = load_model('sla_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = metrics_MLP.values\n",
    "# split into input (X) and output (Y) variables\n",
    "x_input = dataset[:,0:58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[566306.1],\n",
       "       [566306.1],\n",
       "       [566306.1],\n",
       "       [566306.1],\n",
       "       [566306.1],\n",
       "       [566306.1],\n",
       "       [566306.1],\n",
       "       [566306.1],\n",
       "       [566306.1]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.predict(x_input)\n",
    "# 617820"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the problem described in the deliverable that the workers variable is not important to the model and it predicts all the time the same value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## option 2: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>go_goroutines</th>\n",
       "      <th>go_memstats_alloc_bytes</th>\n",
       "      <th>go_memstats_gc_cpu_fraction</th>\n",
       "      <th>go_memstats_gc_sys_bytes</th>\n",
       "      <th>go_memstats_heap_alloc_bytes</th>\n",
       "      <th>go_memstats_heap_idle_bytes</th>\n",
       "      <th>go_memstats_heap_inuse_bytes</th>\n",
       "      <th>go_memstats_heap_objects</th>\n",
       "      <th>go_memstats_heap_released_bytes</th>\n",
       "      <th>go_memstats_heap_sys_bytes</th>\n",
       "      <th>...</th>\n",
       "      <th>node_sockstat_TCP_mem_bytes</th>\n",
       "      <th>node_sockstat_sockets_used</th>\n",
       "      <th>node_time_seconds</th>\n",
       "      <th>node_timex_frequency_adjustment_ratio</th>\n",
       "      <th>node_timex_maxerror_seconds</th>\n",
       "      <th>node_timex_offset_seconds</th>\n",
       "      <th>process_resident_memory_bytes</th>\n",
       "      <th>process_start_time_seconds</th>\n",
       "      <th>workers</th>\n",
       "      <th>exectime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-22 14:10:00</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3442696.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3582216.0</td>\n",
       "      <td>3442696.0</td>\n",
       "      <td>61251584.0</td>\n",
       "      <td>5070848.0</td>\n",
       "      <td>13719.0</td>\n",
       "      <td>60858368.0</td>\n",
       "      <td>66322432.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24576.0</td>\n",
       "      <td>633.0</td>\n",
       "      <td>1.614003e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>25755648.0</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>617820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-22 14:11:00</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3566864.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3582216.0</td>\n",
       "      <td>3566864.0</td>\n",
       "      <td>61079552.0</td>\n",
       "      <td>5210112.0</td>\n",
       "      <td>14196.0</td>\n",
       "      <td>60538880.0</td>\n",
       "      <td>66289664.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24576.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>1.614003e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>25755648.0</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>617820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-22 14:12:00</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3502960.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3582216.0</td>\n",
       "      <td>3502960.0</td>\n",
       "      <td>61300736.0</td>\n",
       "      <td>4988928.0</td>\n",
       "      <td>14424.0</td>\n",
       "      <td>60997632.0</td>\n",
       "      <td>66289664.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45056.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>1.614003e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>25755648.0</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>617820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-22 14:13:00</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2520904.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3582216.0</td>\n",
       "      <td>2520904.0</td>\n",
       "      <td>62070784.0</td>\n",
       "      <td>4186112.0</td>\n",
       "      <td>12789.0</td>\n",
       "      <td>60940288.0</td>\n",
       "      <td>66256896.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36864.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>1.614003e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.1105</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>25755648.0</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>617820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-22 14:14:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3319280.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3582216.0</td>\n",
       "      <td>3319280.0</td>\n",
       "      <td>61366272.0</td>\n",
       "      <td>4923392.0</td>\n",
       "      <td>13443.0</td>\n",
       "      <td>61030400.0</td>\n",
       "      <td>66289664.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28672.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>1.614003e+09</td>\n",
       "      <td>1.000028</td>\n",
       "      <td>0.1405</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>25755648.0</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>617820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-01 09:20:00</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3414888.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3582216.0</td>\n",
       "      <td>3414888.0</td>\n",
       "      <td>61095936.0</td>\n",
       "      <td>5226496.0</td>\n",
       "      <td>12940.0</td>\n",
       "      <td>59523072.0</td>\n",
       "      <td>66322432.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32768.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>1.614590e+09</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>0.2355</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>25243648.0</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>429661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-01 09:21:00</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2825384.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3582216.0</td>\n",
       "      <td>2825384.0</td>\n",
       "      <td>61906944.0</td>\n",
       "      <td>4382720.0</td>\n",
       "      <td>8265.0</td>\n",
       "      <td>60669952.0</td>\n",
       "      <td>66289664.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20480.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>1.614591e+09</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>0.2655</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>25243648.0</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>429661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-01 09:22:00</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2729848.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3582216.0</td>\n",
       "      <td>2729848.0</td>\n",
       "      <td>61972480.0</td>\n",
       "      <td>4284416.0</td>\n",
       "      <td>8005.0</td>\n",
       "      <td>60858368.0</td>\n",
       "      <td>66256896.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20480.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>1.614591e+09</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>0.2955</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>25243648.0</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>429661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-01 09:23:00</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4032792.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3582216.0</td>\n",
       "      <td>4032792.0</td>\n",
       "      <td>60817408.0</td>\n",
       "      <td>5406720.0</td>\n",
       "      <td>20776.0</td>\n",
       "      <td>60063744.0</td>\n",
       "      <td>66224128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36864.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>1.614591e+09</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>0.3255</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>25243648.0</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>429661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-01 09:24:00</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3483000.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3582216.0</td>\n",
       "      <td>3483000.0</td>\n",
       "      <td>61095936.0</td>\n",
       "      <td>5160960.0</td>\n",
       "      <td>13670.0</td>\n",
       "      <td>60743680.0</td>\n",
       "      <td>66256896.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45056.0</td>\n",
       "      <td>742.0</td>\n",
       "      <td>1.614591e+09</td>\n",
       "      <td>1.000027</td>\n",
       "      <td>0.3555</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>25243648.0</td>\n",
       "      <td>1.612092e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>429661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     go_goroutines  go_memstats_alloc_bytes  \\\n",
       "timestamp                                                     \n",
       "2021-02-22 14:10:00            7.0                3442696.0   \n",
       "2021-02-22 14:11:00            7.0                3566864.0   \n",
       "2021-02-22 14:12:00            7.0                3502960.0   \n",
       "2021-02-22 14:13:00            7.0                2520904.0   \n",
       "2021-02-22 14:14:00            8.0                3319280.0   \n",
       "...                            ...                      ...   \n",
       "2021-03-01 09:20:00            7.0                3414888.0   \n",
       "2021-03-01 09:21:00            7.0                2825384.0   \n",
       "2021-03-01 09:22:00            7.0                2729848.0   \n",
       "2021-03-01 09:23:00            7.0                4032792.0   \n",
       "2021-03-01 09:24:00            7.0                3483000.0   \n",
       "\n",
       "                     go_memstats_gc_cpu_fraction  go_memstats_gc_sys_bytes  \\\n",
       "timestamp                                                                    \n",
       "2021-02-22 14:10:00                     0.000015                 3582216.0   \n",
       "2021-02-22 14:11:00                     0.000015                 3582216.0   \n",
       "2021-02-22 14:12:00                     0.000015                 3582216.0   \n",
       "2021-02-22 14:13:00                     0.000015                 3582216.0   \n",
       "2021-02-22 14:14:00                     0.000015                 3582216.0   \n",
       "...                                          ...                       ...   \n",
       "2021-03-01 09:20:00                     0.000015                 3582216.0   \n",
       "2021-03-01 09:21:00                     0.000015                 3582216.0   \n",
       "2021-03-01 09:22:00                     0.000015                 3582216.0   \n",
       "2021-03-01 09:23:00                     0.000015                 3582216.0   \n",
       "2021-03-01 09:24:00                     0.000015                 3582216.0   \n",
       "\n",
       "                     go_memstats_heap_alloc_bytes  \\\n",
       "timestamp                                           \n",
       "2021-02-22 14:10:00                     3442696.0   \n",
       "2021-02-22 14:11:00                     3566864.0   \n",
       "2021-02-22 14:12:00                     3502960.0   \n",
       "2021-02-22 14:13:00                     2520904.0   \n",
       "2021-02-22 14:14:00                     3319280.0   \n",
       "...                                           ...   \n",
       "2021-03-01 09:20:00                     3414888.0   \n",
       "2021-03-01 09:21:00                     2825384.0   \n",
       "2021-03-01 09:22:00                     2729848.0   \n",
       "2021-03-01 09:23:00                     4032792.0   \n",
       "2021-03-01 09:24:00                     3483000.0   \n",
       "\n",
       "                     go_memstats_heap_idle_bytes  \\\n",
       "timestamp                                          \n",
       "2021-02-22 14:10:00                   61251584.0   \n",
       "2021-02-22 14:11:00                   61079552.0   \n",
       "2021-02-22 14:12:00                   61300736.0   \n",
       "2021-02-22 14:13:00                   62070784.0   \n",
       "2021-02-22 14:14:00                   61366272.0   \n",
       "...                                          ...   \n",
       "2021-03-01 09:20:00                   61095936.0   \n",
       "2021-03-01 09:21:00                   61906944.0   \n",
       "2021-03-01 09:22:00                   61972480.0   \n",
       "2021-03-01 09:23:00                   60817408.0   \n",
       "2021-03-01 09:24:00                   61095936.0   \n",
       "\n",
       "                     go_memstats_heap_inuse_bytes  go_memstats_heap_objects  \\\n",
       "timestamp                                                                     \n",
       "2021-02-22 14:10:00                     5070848.0                   13719.0   \n",
       "2021-02-22 14:11:00                     5210112.0                   14196.0   \n",
       "2021-02-22 14:12:00                     4988928.0                   14424.0   \n",
       "2021-02-22 14:13:00                     4186112.0                   12789.0   \n",
       "2021-02-22 14:14:00                     4923392.0                   13443.0   \n",
       "...                                           ...                       ...   \n",
       "2021-03-01 09:20:00                     5226496.0                   12940.0   \n",
       "2021-03-01 09:21:00                     4382720.0                    8265.0   \n",
       "2021-03-01 09:22:00                     4284416.0                    8005.0   \n",
       "2021-03-01 09:23:00                     5406720.0                   20776.0   \n",
       "2021-03-01 09:24:00                     5160960.0                   13670.0   \n",
       "\n",
       "                     go_memstats_heap_released_bytes  \\\n",
       "timestamp                                              \n",
       "2021-02-22 14:10:00                       60858368.0   \n",
       "2021-02-22 14:11:00                       60538880.0   \n",
       "2021-02-22 14:12:00                       60997632.0   \n",
       "2021-02-22 14:13:00                       60940288.0   \n",
       "2021-02-22 14:14:00                       61030400.0   \n",
       "...                                              ...   \n",
       "2021-03-01 09:20:00                       59523072.0   \n",
       "2021-03-01 09:21:00                       60669952.0   \n",
       "2021-03-01 09:22:00                       60858368.0   \n",
       "2021-03-01 09:23:00                       60063744.0   \n",
       "2021-03-01 09:24:00                       60743680.0   \n",
       "\n",
       "                     go_memstats_heap_sys_bytes  ...  \\\n",
       "timestamp                                        ...   \n",
       "2021-02-22 14:10:00                  66322432.0  ...   \n",
       "2021-02-22 14:11:00                  66289664.0  ...   \n",
       "2021-02-22 14:12:00                  66289664.0  ...   \n",
       "2021-02-22 14:13:00                  66256896.0  ...   \n",
       "2021-02-22 14:14:00                  66289664.0  ...   \n",
       "...                                         ...  ...   \n",
       "2021-03-01 09:20:00                  66322432.0  ...   \n",
       "2021-03-01 09:21:00                  66289664.0  ...   \n",
       "2021-03-01 09:22:00                  66256896.0  ...   \n",
       "2021-03-01 09:23:00                  66224128.0  ...   \n",
       "2021-03-01 09:24:00                  66256896.0  ...   \n",
       "\n",
       "                     node_sockstat_TCP_mem_bytes  node_sockstat_sockets_used  \\\n",
       "timestamp                                                                      \n",
       "2021-02-22 14:10:00                      24576.0                       633.0   \n",
       "2021-02-22 14:11:00                      24576.0                       634.0   \n",
       "2021-02-22 14:12:00                      45056.0                       636.0   \n",
       "2021-02-22 14:13:00                      36864.0                       634.0   \n",
       "2021-02-22 14:14:00                      28672.0                       634.0   \n",
       "...                                          ...                         ...   \n",
       "2021-03-01 09:20:00                      32768.0                       670.0   \n",
       "2021-03-01 09:21:00                      20480.0                       667.0   \n",
       "2021-03-01 09:22:00                      20480.0                       670.0   \n",
       "2021-03-01 09:23:00                      36864.0                       667.0   \n",
       "2021-03-01 09:24:00                      45056.0                       742.0   \n",
       "\n",
       "                     node_time_seconds  node_timex_frequency_adjustment_ratio  \\\n",
       "timestamp                                                                       \n",
       "2021-02-22 14:10:00       1.614003e+09                               1.000028   \n",
       "2021-02-22 14:11:00       1.614003e+09                               1.000028   \n",
       "2021-02-22 14:12:00       1.614003e+09                               1.000028   \n",
       "2021-02-22 14:13:00       1.614003e+09                               1.000028   \n",
       "2021-02-22 14:14:00       1.614003e+09                               1.000028   \n",
       "...                                ...                                    ...   \n",
       "2021-03-01 09:20:00       1.614590e+09                               1.000027   \n",
       "2021-03-01 09:21:00       1.614591e+09                               1.000027   \n",
       "2021-03-01 09:22:00       1.614591e+09                               1.000027   \n",
       "2021-03-01 09:23:00       1.614591e+09                               1.000027   \n",
       "2021-03-01 09:24:00       1.614591e+09                               1.000027   \n",
       "\n",
       "                     node_timex_maxerror_seconds  node_timex_offset_seconds  \\\n",
       "timestamp                                                                     \n",
       "2021-02-22 14:10:00                       0.0205                  -0.000161   \n",
       "2021-02-22 14:11:00                       0.0505                  -0.000143   \n",
       "2021-02-22 14:12:00                       0.0805                  -0.000127   \n",
       "2021-02-22 14:13:00                       0.1105                  -0.000113   \n",
       "2021-02-22 14:14:00                       0.1405                  -0.000100   \n",
       "...                                          ...                        ...   \n",
       "2021-03-01 09:20:00                       0.2355                   0.000335   \n",
       "2021-03-01 09:21:00                       0.2655                   0.000298   \n",
       "2021-03-01 09:22:00                       0.2955                   0.000265   \n",
       "2021-03-01 09:23:00                       0.3255                   0.000235   \n",
       "2021-03-01 09:24:00                       0.3555                   0.000209   \n",
       "\n",
       "                     process_resident_memory_bytes  \\\n",
       "timestamp                                            \n",
       "2021-02-22 14:10:00                     25755648.0   \n",
       "2021-02-22 14:11:00                     25755648.0   \n",
       "2021-02-22 14:12:00                     25755648.0   \n",
       "2021-02-22 14:13:00                     25755648.0   \n",
       "2021-02-22 14:14:00                     25755648.0   \n",
       "...                                            ...   \n",
       "2021-03-01 09:20:00                     25243648.0   \n",
       "2021-03-01 09:21:00                     25243648.0   \n",
       "2021-03-01 09:22:00                     25243648.0   \n",
       "2021-03-01 09:23:00                     25243648.0   \n",
       "2021-03-01 09:24:00                     25243648.0   \n",
       "\n",
       "                     process_start_time_seconds  workers  exectime  \n",
       "timestamp                                                           \n",
       "2021-02-22 14:10:00                1.612092e+09        3    617820  \n",
       "2021-02-22 14:11:00                1.612092e+09        3    617820  \n",
       "2021-02-22 14:12:00                1.612092e+09        3    617820  \n",
       "2021-02-22 14:13:00                1.612092e+09        3    617820  \n",
       "2021-02-22 14:14:00                1.612092e+09        3    617820  \n",
       "...                                         ...      ...       ...  \n",
       "2021-03-01 09:20:00                1.612092e+09        9    429661  \n",
       "2021-03-01 09:21:00                1.612092e+09        9    429661  \n",
       "2021-03-01 09:22:00                1.612092e+09        9    429661  \n",
       "2021-03-01 09:23:00                1.612092e+09        9    429661  \n",
       "2021-03-01 09:24:00                1.612092e+09        9    429661  \n",
       "\n",
       "[2400 rows x 59 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_MLP = new_df_array[0]\n",
    "metrics_MLP[\"workers\"] = workers[0]\n",
    "metrics_MLP[\"exectime\"] = exectimes[0]\n",
    "for i in range(1,len(new_df_array)):\n",
    "    local_df = new_df_array[i]\n",
    "    local_df[\"workers\"] = workers[i]\n",
    "    local_df[\"exectime\"] = exectimes[i]\n",
    "    metrics_MLP = metrics_MLP.append(local_df)\n",
    "    \n",
    "metrics_MLP.set_index('timestamp', inplace=True)\n",
    "\n",
    "metrics_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaler to tranform the input to something more readable for neural networks models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scaled to work with Neural networks.\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([617820., 617820., 617820., ..., 429661., 429661., 429661.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_dataset = metrics_MLP\n",
    "for metric_name in metrics_names:    \n",
    "    pre_dataset[metric_name] = scaler.fit_transform(pre_dataset[metric_name].values.reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "dataset = pre_dataset.values\n",
    "x_train = dataset[:,0:58]\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "#y_train = exectimes\n",
    "y_train = dataset[:,58]\n",
    "\n",
    "print(y_train.shape)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "dataset_train = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    sequence_length=60,\n",
    "    sequence_stride=60,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([617820., 571378., 566439., 564199., 578790., 567978., 565619.,\n",
       "       565052., 572151., 582628., 636311., 593063., 522618., 454466.,\n",
       "       464412., 464266., 455849., 466922., 468000., 709955., 693223.,\n",
       "       595968., 463951., 455543., 472430., 459940., 588759., 600364.,\n",
       "       594230., 599054., 457041., 464953., 407144., 415762., 416799.,\n",
       "       424616., 413798., 416003., 411904., 429661.])"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    sequence_length=60,\n",
    "    sequence_stride=60,\n",
    "    shuffle=False,\n",
    "#    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (40, 60, 58)\n",
      "Target shape: (40,)\n"
     ]
    }
   ],
   "source": [
    "for batch in dataset_train.take(1):\n",
    "    inputs, targets = batch\n",
    "\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define different LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model_1(inputs,outputs):\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
    "    lstm_out = tf.keras.layers.LSTM(60)(inputs)\n",
    "    outputs = tf.keras.layers.Dense(1)(lstm_out)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model_2(inputs,outputs):\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    # Create the Keras model.\n",
    "    # Use hyperparameter optimization if you have the time.\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
    "\n",
    "    # units=10 -> The cell and hidden states will be of dimension 10.\n",
    "    #             The number of parameters that need to be trained = 4*units*(units+2)\n",
    "    x = tf.keras.layers.LSTM(units=10)(inputs)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # Specify the training configuration.\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['mse'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model_3(inputs,outputs):\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
    "    x = tf.keras.layers.LSTM(10, activation='relu', return_sequences=True)(inputs)\n",
    "    x = tf.keras.layers.LSTM(5, activation='relu', return_sequences=True)(x)\n",
    "    x = tf.keras.layers.LSTM(1, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # Specify the training configuration.\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['mse'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        [(None, 60, 58)]          0         \n",
      "_________________________________________________________________\n",
      "lstm_40 (LSTM)               (None, 60, 10)            2760      \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, 60, 5)             320       \n",
      "_________________________________________________________________\n",
      "lstm_42 (LSTM)               (None, 1)                 28        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 3,110\n",
      "Trainable params: 3,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = LSTM_model_1(inputs,outputs)\n",
    "#model = LSTM_model_2(inputs,outputs)\n",
    "model = LSTM_model_3(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 265721741312.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 265721741312.00000 to 255468470272.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 255468470272.00000 to 245621276672.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 245621276672.00000 to 236164005888.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 236164005888.00000 to 227081240576.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 227081240576.00000 to 218358202368.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 218358202368.00000 to 209980555264.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00008: val_loss improved from 209980555264.00000 to 201934667776.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00009: val_loss improved from 201934667776.00000 to 194207383552.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 194207383552.00000 to 186786136064.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00011: val_loss improved from 186786136064.00000 to 179658719232.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00012: val_loss improved from 179658719232.00000 to 172813582336.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00013: val_loss improved from 172813582336.00000 to 166239502336.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00014: val_loss improved from 166239502336.00000 to 159925764096.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00015: val_loss improved from 159925764096.00000 to 153862045696.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00016: val_loss improved from 153862045696.00000 to 148038451200.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00017: val_loss improved from 148038451200.00000 to 142445477888.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00018: val_loss improved from 142445477888.00000 to 137073967104.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00019: val_loss improved from 137073967104.00000 to 131915210752.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00020: val_loss improved from 131915210752.00000 to 126960689152.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00021: val_loss improved from 126960689152.00000 to 122202382336.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00022: val_loss improved from 122202382336.00000 to 117632516096.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00023: val_loss improved from 117632516096.00000 to 113243611136.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00024: val_loss improved from 113243611136.00000 to 109028524032.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00025: val_loss improved from 109028524032.00000 to 104980324352.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00026: val_loss improved from 104980324352.00000 to 101092442112.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00027: val_loss improved from 101092442112.00000 to 97358528512.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00028: val_loss improved from 97358528512.00000 to 93772488704.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00029: val_loss improved from 93772488704.00000 to 90328424448.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00030: val_loss improved from 90328424448.00000 to 87020773376.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00031: val_loss improved from 87020773376.00000 to 83844079616.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00032: val_loss improved from 83844079616.00000 to 80793214976.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00033: val_loss improved from 80793214976.00000 to 77863141376.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00034: val_loss improved from 77863141376.00000 to 75049107456.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00035: val_loss improved from 75049107456.00000 to 72346501120.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00036: val_loss improved from 72346501120.00000 to 69750931456.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00037: val_loss improved from 69750931456.00000 to 67258142720.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00038: val_loss improved from 67258142720.00000 to 64864051200.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00039: val_loss improved from 64864051200.00000 to 62564786176.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00040: val_loss improved from 62564786176.00000 to 60356558848.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00041: val_loss improved from 60356558848.00000 to 58235789312.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00042: val_loss improved from 58235789312.00000 to 56199000064.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00043: val_loss improved from 56199000064.00000 to 54242873344.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00044: val_loss improved from 54242873344.00000 to 52364189696.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00045: val_loss improved from 52364189696.00000 to 50559901696.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00046: val_loss improved from 50559901696.00000 to 48827080704.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00047: val_loss improved from 48827080704.00000 to 47162867712.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00048: val_loss improved from 47162867712.00000 to 45564559360.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00049: val_loss improved from 45564559360.00000 to 44029546496.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00050: val_loss improved from 44029546496.00000 to 42555318272.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00051: val_loss improved from 42555318272.00000 to 41139478528.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00052: val_loss improved from 41139478528.00000 to 39779696640.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00053: val_loss improved from 39779696640.00000 to 38473768960.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00054: val_loss improved from 38473768960.00000 to 37219545088.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00055: val_loss improved from 37219545088.00000 to 36014993408.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00056: val_loss improved from 36014993408.00000 to 34858147840.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00057: val_loss improved from 34858147840.00000 to 33747101696.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00058: val_loss improved from 33747101696.00000 to 32680056832.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00059: val_loss improved from 32680056832.00000 to 31655270400.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00060: val_loss improved from 31655270400.00000 to 30671071232.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00061: val_loss improved from 30671071232.00000 to 29725841408.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00062: val_loss improved from 29725841408.00000 to 28818040832.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00063: val_loss improved from 28818040832.00000 to 27946188800.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00064: val_loss improved from 27946188800.00000 to 27108855808.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00065: val_loss improved from 27108855808.00000 to 26304692224.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00066: val_loss improved from 26304692224.00000 to 25532370944.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00067: val_loss improved from 25532370944.00000 to 24790628352.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00068: val_loss improved from 24790628352.00000 to 24078264320.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00069: val_loss improved from 24078264320.00000 to 23394105344.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00070: val_loss improved from 23394105344.00000 to 22737039360.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00071: val_loss improved from 22737039360.00000 to 22105997312.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00072: val_loss improved from 22105997312.00000 to 21499940864.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00073: val_loss improved from 21499940864.00000 to 20917882880.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00074: val_loss improved from 20917882880.00000 to 20358875136.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00075: val_loss improved from 20358875136.00000 to 19822006272.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00076: val_loss improved from 19822006272.00000 to 19306401792.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00077: val_loss improved from 19306401792.00000 to 18811211776.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00078: val_loss improved from 18811211776.00000 to 18335625216.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00079: val_loss improved from 18335625216.00000 to 17878876160.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00080: val_loss improved from 17878876160.00000 to 17440217088.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00081: val_loss improved from 17440217088.00000 to 17018927104.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00082: val_loss improved from 17018927104.00000 to 16614320128.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00083: val_loss improved from 16614320128.00000 to 16225733632.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00084: val_loss improved from 16225733632.00000 to 15852538880.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00085: val_loss improved from 15852538880.00000 to 15494122496.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00086: val_loss improved from 15494122496.00000 to 15149896704.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00087: val_loss improved from 15149896704.00000 to 14819305472.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00088: val_loss improved from 14819305472.00000 to 14501803008.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00089: val_loss improved from 14501803008.00000 to 14196870144.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00090: val_loss improved from 14196870144.00000 to 13904019456.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00091: val_loss improved from 13904019456.00000 to 13622760448.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00092: val_loss improved from 13622760448.00000 to 13352641536.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00093: val_loss improved from 13352641536.00000 to 13093218304.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00094: val_loss improved from 13093218304.00000 to 12844067840.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00095: val_loss improved from 12844067840.00000 to 12604787712.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00096: val_loss improved from 12604787712.00000 to 12374982656.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00097: val_loss improved from 12374982656.00000 to 12154277888.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00098: val_loss improved from 12154277888.00000 to 11942309888.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00099: val_loss improved from 11942309888.00000 to 11738738688.00000, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch 00100: val_loss improved from 11738738688.00000 to 11543226368.00000, saving model to model_checkpoint.h5\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "path_checkpoint = \"model_checkpoint.h5\"\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5)\n",
    "\n",
    "modelckpt_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=path_checkpoint,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=dataset_val,\n",
    "    callbacks=[es_callback, modelckpt_callback],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_loss(history, title):\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(len(loss))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_loss(history, \"Training and Validation Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([617820., 617820., 617820., 617820., 617820., 617820., 617820.,\n",
       "       617820., 617820., 617820., 617820., 617820., 617820., 617820.,\n",
       "       617820., 617820., 617820., 617820., 617820., 617820., 617820.,\n",
       "       617820., 617820., 617820., 617820., 617820., 617820., 617820.,\n",
       "       617820., 617820., 617820., 617820., 617820., 617820., 617820.,\n",
       "       617820., 617820., 617820., 617820., 617820., 617820., 617820.,\n",
       "       617820., 617820., 617820., 617820., 617820., 617820., 617820.,\n",
       "       617820., 617820., 617820., 617820., 617820., 617820., 617820.,\n",
       "       617820., 617820., 617820., 617820.])"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_datasetpred = metrics_MLP\n",
    "for metric_name in metrics_names:    \n",
    "    pre_datasetpred[metric_name] = scaler.fit_transform(pre_datasetpred[metric_name].values.reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "datasetpred = pre_datasetpred.values[0:60]\n",
    "x_test = datasetpred[:,0:58]\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "y_test = datasetpred[:,58]\n",
    "\n",
    "print(y_test.shape)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last result shows that we have the same problem as before, all the time the same exectime for different workers values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.58961295, 0.18279603, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.63751165, 0.19731355, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.61286022, 0.23499123, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [1.        , 0.804418  , 0.73492963, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.47502453, 0.95640859, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.32750171, 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    sequence_length=60,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1, 60, 58)\n",
      "Target shape: (1,)\n"
     ]
    }
   ],
   "source": [
    "x_pred = \"\"\n",
    "y_pred = \"\"\n",
    "for batch in dataset_test.take(1):\n",
    "    x_pred, y_pred = batch\n",
    "\n",
    "print(\"Input shape:\", x_pred.numpy().shape)\n",
    "print(\"Target shape:\", y_pred.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[617820.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[450366.94]], dtype=float32)"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_pred.numpy())\n",
    "model.predict(x_pred)\n",
    "# 617820"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
